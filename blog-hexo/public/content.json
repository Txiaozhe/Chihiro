{"meta":{"title":"Jim Tang's blog","subtitle":"","description":"","author":"Jim Tang","url":"https://txiaozhe.github.io","root":"/"},"posts":[{"tags":[{"name":"Life","slug":"Life","permalink":"https://txiaozhe.github.io/tags/Life/"},{"name":"Job","slug":"Job","permalink":"https://txiaozhe.github.io/tags/Job/"}],"title":"关于一段现在已经不太提起的经历，以及我眼中的创业","date":"2020/03/07","text":"从 2019 年年底我开始整理一些过去的经历，参与过的项目，做过的工作及细节。可能一方面源于我本身也是一个容易怀念的人，另一方面也希望站在当下回望过去，在这个略显迷茫的时期为未来找一些新的思考方向。之前复盘的内容大多涉及技术，其中不乏各种程序员专有名词、技术术语和解决方案。但在思考当下碰到的瓶颈的时候，发现可能我要解决的问题并非只有技术那么简单。回望一下不是很久远的过去，有那么一段经历现在已经不太提起了，但在我心里，这无疑是我人生中无法回避的一个重大转折点。 回到 2015 年冬天，大二，化学专业。虽然身在化学学院，但我在学院内一直是一个不太一样的存在，在老师和同学们的眼里，我不好好学习，但爱瞎琢磨，尤其对电脑技术。那时候的我确实也是如此，对待化学内容得过且过 60 分万岁，对计算机技术却趋之若鹜，且时常与一群计算机学院的学生玩在一起，并在一个偶然的机会下认识了一个在当地大学科技园创业的团队。 在当时我的眼光下，这无疑是一支大神团队。创始人涛哥，英国名校海归硕士；技术负责人飞哥，工信部研究所硕士，前摩托罗拉、飞思卡尔等名企高级工程师；何工，高级工程师；财务、后勤负责人老张，中国移动，另加两位职员。当时他们主营业务主要是与发电厂合作研发数控软件系统，并逐渐有一些互联网方向的探索。 回想起那个时候我是一个特别勤奋自律的学生，虽然每天上学都被各种课程充斥，但每当有半天空闲时我就会往大学科技园奔去。在团队内部，我的角色是实习生，但他们也从来也不见外，在那里，我一方面接受他们给我的计算机技术指导，另一方面也参与他们的团建与日常活动，团队的概念第一次在我脑中成型，也让我更加增强了走技术研发道路的信心。 时间一转眼来到 2016 年夏天，半年多的相处，实质上我已成为团队的一员。当年暑假理所应当地留在了那里继续实习生活。但对于我自己手上在做的工作，那时候的我其实并没有太多的理解与思考。对于当时团队碰到的困境，有一些我也是看在眼里的。那个时候全国都在高喊 ”大众创业，万众创新“，互联网+、O2O、共享经济是最热的词，彼时比特币还没上天，众多路演的创业明星光鲜亮丽，走到台前发表让人热血沸腾的计划与愿景。这是最初我眼中创业该有的样子。但彼时彼刻我看到的却是公司主营业务问题频发难以为继，未来创业方向无法明确，团队内部开始争论与动摇，还有人的问题，钱的问题。 也许当时是在做一些尝试的。先解决人的问题。 时值暑假，且凭借良好的高校关系，我们从一所 211 大学招到十几位实习生来做事。招实习生的动作其实也是无奈之举，他们没有工作经验，没有技术实力，但好在，他们省钱。团队扩充到近 20 人，大学科技园分配的座位显然不够用了，于是团队整体搬到了一处民宅内，条件艰苦但也算不错的解决方案，嗯，开始有点车库创业的意思了。 为了让实习生们能快速形成战斗力，我们开始针对实习生进行一系列培训，根据个人意愿自由选择产品、技术或设计方向。所幸我们找到的学生大多成绩优秀，培训起来并没有太多障碍，且大多具有非常主动的学习意识。这其实也是一个筛选的过程，渐渐地无法跟上学习进度的学生开始退出，我们也相信留下来的学生一定是最优秀的。那段时间可能是整个经历中最平稳最充实的一段了吧，虽然业务方向仍然没有明确，但好歹团队内部每个人都在各司其职，团队信心开始慢慢提升。 或许是被他们看到了我的认真与付出，最终他们邀请我加入团队成为创业团队的一员。当时我大三，那个时候的我，对于创业仍然没有太明确的认知，对团队无法做到真正认同，对于业务的思考也几乎为零。但在一系列谨慎的思考后，我仍然签署了合同。团队给我分配的工作是负责实习生队伍的建设。 很快，留下来的实习生开始逐渐能参与正式业务。接下来还有最紧要的问题，钱的问题。 一切都是为了生存。当地一个农民团体组织计划把农民、农村搬上互联网，他们有资源有钱，我们有产品和技术方案，两边一拍即合。最初我们的角色还是一个外包团队，我们提供互联网技术，为他们打造他们想要的产品。但逐渐地，对方发现外包的模式无法产出优异的产品，于是打算把我们吸收。经过一系列讨论和谈判，最终达成合作。而对我们来说，算是短期解决了资金问题。 看上去团队已经暂时解决了温饱问题，但其实我们都知道，这不是我们想要的结果。且随后的合作过程也并不顺畅，逐渐地两边人的互联网认知差异开始显现，产品观念和方案也开始出现分歧，且从一开始对方的互联网化信念其实也没有太坚实，眼看着合作的道路越来越窄，而此时，团队内部也开始出现争论，到底是继续从事外包先养活自己，还是集中精力思考下一步方向。 理想总是要败给现实的。团队还要养活，还需要钱。之后的外包项目中，有与发电厂合作开发软件控制系统，有与有色金属回收厂商合作，为其开发在线有色金属交易平台，也有与高校合作为其校内项目开发产品，算是解了燃眉之急。 时间转眼来到 2017 年，毕业季。暂且放下团队内部的事务，也暂时不参与产品开发，我开始把大量时间用于毕业设计。但当时团队内部的争论和矛盾却越发凸显。一方面养活自己的现实任务仍然沉重，另一方面也为团队的未来而担忧，经历了一年多以外包为主营业务的创业生涯，团队成员也有了更多的思考，明确公司未来方向成为首要任务。在不间断的讨论与思考中，团队逐渐形成了共识，其实大家一直都忽略了一个事实，当时我们用的设计和开发力量都是我们自己培训出来的学生，包括我自己，我们发现其实我们拥有很强的培训能力，而且我们在技术上一直紧跟互联网技术发展的风潮，那何不将培训作为我们下一阶段的努力方向，打造紧跟互联网技术潮流的高端技术培训业务。很快，这个想法成为了团队的共识，大家似乎一下子有了明确的努力方向。 很快，我毕业了。因为看到了团队的改变，也有了明确的方向，于是我决定留下。我们开始将第一批培训的十几名实习生往外输送，一方面想看看市场反响，另一方面也往外布局，给团队增强信心。第一批出去的学生果然不负众望，有多个被阿里、华为、金山等大厂录用，剩余的也基本拿到了不错的薪资，团队信心高涨。制作海报、宣传、招生、培训工作开始逐步进行。 很快，一个最大的问题出现了，我们没有培训资质。但申请正常的培训资质有各种门槛限制，若依附于其他有资质的机构也面临各种限制和资金问题，无奈。所幸我们有不错的高校资源，于是我们开始私下小规模招生，收取少量培训费，收入不高但也算逐步展开业务。原以为培训业务会逐步展开且越来越好，但其后一个意想不到的问题发生了，一位学生看了我们的招生宣传后质疑我们的培训资质，于是向学校举报。团队业务算是迎来一个始料未及的挑战。而此时，一个更大的问题又暴露出来了，原先实习生已经输出，团队内部开发力量紧缺，外包无法跟进，团队又面临资金问题。 创业的道路越发艰难，外部持续爆发问题，内部人员开始动摇，相继有核心成员离开团队。面对团队外部内部无法解决的各种问题，我开始感到前所未有的心累，身处其中却只能作为旁观者。后来，我开始考虑退出。2017 年国庆，趁着休假，开始思考下一步计划。带着准备好的简历来到杭州面试找工作。在碰了一系列的壁之后，只身前往苏州看望朋友，而后回家。2017 年 10 月底，回到团队所在地，正式提出退出申请。 再次回到杭州的前一天晚上，团队所有成员，以及当时出去的实习生，大家坐在一张桌子上吃饭，为我送行，气氛很尴尬。我想他们心里是有怨气的。吃完饭回到住处的路上，我扶着一棵树，痛哭流涕。 对于创业这件事，也许我是有切身体会的。没有掌声，没有光环，有的只是空洞的梦想、还有各种问题。但这次经历无疑是我人生中无法忘却和抹去的重要一笔。","permalink":"https://txiaozhe.github.io/2020/03/07/my-entrepreneurship/","photos":[]},{"tags":[{"name":"IoT","slug":"IoT","permalink":"https://txiaozhe.github.io/tags/IoT/"}],"title":"复盘2：IoT + 教育培训业务架构设计","date":"2020/02/29","text":"2019 年 9月底，由于公司业务原因从 Rokid 离职，十月份则到处跑找工作，因此也接触到一些公司和创始人，期间碰到一家做 IoT + 编程教育的初创公司，对于他们的业务目标目前他们没有足够的相关经验来搭建，并且他们也比较认可我所描述的一套 IoT 业务流程，聊过之后发现有合作的可能，因此尝试为他们设计整体业务的架构方案。 本文是我针对他们的业务场景给出的架构设计方案描述以及我个人的一些对 IoT、社区生态方面的思考。 公司及业务背景对方是一家初创公司，创始人来自中国移动杭州研发中心，据他描述目前团队成员3人左右，创业方向为面向小学阶段的 IoT + 教育培训，简单来说就是在传统的编程教育基础上加入 IoT 元素。 关于业务模式和架构主要分为两种：一种是纯粹面向IoT设备编程，考虑采用 Python（因为据说目前中小学比较普及 Python 这种语言），具体 IoT 设备会包括高端的比如天猫精灵、米家等各种设备，以及也会包括一些更低端的小设备比如 Arduino 及相关小型组件、树莓派等，让学生通过简单编程实现对设备的控制（简单思考下来觉得这跟传统的少儿编程模式比还是有一些优势的，毕竟少儿编程教育主要为激发学生兴趣和思维，这种带有实实在在设备的模式对于小孩子来说可能会更有吸引力），这个过程需要平台对设备的封装管理和虚拟化； 另一种模式则涉及到一种图形化编程工具平台：Scratch，这种模式其实也算是对第一种模式的更深层次抽象，或者说将采用 Python 语言编程的模式改为图形化编程操作，其他基本不变，这可能是更容易让幼儿阶段的孩子接受的培训方式，这也涉及到他们一直提的概念：软件积木，目前他们手上有一些教育资源和培训机构合作关系，且初步的少儿编程教育业务已经在开展，下一步就是真正实现 IoT + 编程培训。关于 Scratch 的对接方式他们目前已经有一些技术基础，两种模式下业务架构上对 IoT 设备的管理和虚拟化也基本一致，因此这个方案主要是为业务中用到的各种设备建立管理和控制平台。 整体方案概览架构图 设计方案简介一、总体服务分为三层：用户层、服务层、设备层 1、用户层：提供统一的对外服务，包括管理员界面、用户（学生）编程控制界面及教学工具、数据工具等 2、服务层（分为三部分）： ​ 2.1、自有 IoT 服务：将所有设备进行虚拟化控制与管理，并承担与三方 IoT 云服务对接的功能。 ​ 2.2、三方 IoT 服务：三方厂商的 IoT 云服务，如米家云服务，这部分无需研发，需要做的主要工作为协议对接。 ​ 2.3、API：将自有 IoT 服务与三方 IoT 服务的对外功能与数据通道进行统一封装并对外提供一致的服务，实现业务与应用之间的解耦。 3、设备层（整合业务中需要用到的所有设备，并将所有设备按来源与管理方式分为三类）： ​ 3.1、自定义设备：需要自主编程控制并直接通过自有 IoT 服务管理的设备，如 Arduino、树莓派及其相关子设备等。 ​ 3.2、三方设备：来自于第三方厂商，需要间接通过第三方 IoT 服务进行管理与控制，如米家设备等。 ​ 3.3、虚拟设备：由于在服务层已经将所有设备进行虚拟化，因此在某些业务场景下可以创建虚拟设备而无需提供真实的物理设备，这种设备除了没有物理机身外其他管理和控制的流程都与上述自定义设备一致。 二、本方案中主要业务流程为设备管理、设备查询、设备控制、数据通道，网络协议采用MQTT。 1、设备管理 业务中需要用到的各种设备都需要系统管理员通过管理界面进行管理，包括设备的添加与删除，IoT服务端会维护一个可供管理和控制的设备列表。对于一些三方设备如米家设备通信时会涉及驱动，这里的驱动将常驻于云端并与三方厂商云端进行云云对接，由于这里的场景下设备的添加删除操作不频繁，因此暂不考虑驱动按需安装和卸载的场景。驱动的主要功能是作为本地系统与三方云厂商进行协议对接的代理，其中会涉及鉴权流程，需根据不同平台进行对接。 设备管理案例（添加设备）流程图： 2、设备查询 设备查询主要用于在管理员界面显示当前系统支持管理控制的所有设备以及为用户（学生）提供可视化的操作界面。 3、设备控制 设备控制流程与普通IoT设备的控制流程基本一致，但指令的输入方式不一样，主要为用户（学生）在预先设定好的操作界面上通过点击、拖动的方式来进行设备的控制，控制指令由用户界面上传至云端，云端会根据协议内容选择对应的设备下发指令由设备执行，控制结果由设备上报至云端，再由云端反馈给用户端。 4、数据通道 此功能用于聚合所有用户（学生）在教学和使用过程中产生的操作和控制数据，为后期教学和运营提供数据依据。 业务流程举例例如一块 Arduino 的板子 A 上连接了一个发光二极管 R 和一个蜂鸣器 F，R 和 F 皆可通过 A 控制。云端服务已事先定义好与 A 之间的通信协议。当 A 上的程序启动时，A 会与云端建立连接，此时系统管理员可通过管理界面请求将A添加到云端设备列表中，A 会反馈给云端其携带的各种子设备，云端确认后将 A 及 A 的子设备 R 和 F 添加至可控制的设备列表中，此时用户（学生）的界面中也能显示这些虚拟化的设备。当用户（学生）点击页面上的虚拟设备操控按钮时，页面将相应的操作指令上传至云端，由云端下发至设备上执行操作，操作完后设备向云端反馈操作结果，最终操作结果反馈至用户界面，并同时保留相应操作数据。 问题与思考1、经过三次的交谈，从技术层面上考虑，除去 IoT 设计开发经验的缺乏，我认为他们目前也还是面临一些问题的，比如面向设备端（前期主要为 Arduino 和树莓派）编程的时候其实没有太多的选择，因此也曾向团队推荐使用 Rokid 自研的 YodaOS + ShadowNode 或 ShadowNode 来作为设备端的解决方案，在我整体的介绍之后，对方也认可这样能降低整体的开发难度和成本，提高研发效率，但总体来说采用的意愿却并不是很强。其中一个原因是对性能的担忧，还有一些未知的因素，我觉得这也是作为开源平台方需要思考的问题。 2、关于社会编程教育的思考，上述这一套 IoT + 编程教育模式细节不再多说，目前市面上面向少儿的编程教育目标与成人编程不同，前者主要是激发孩子兴趣和锻炼思维，对于受众来说没有特别清晰明确的教育目标，当然也会受普世的教育价值观导向比如高考的影响。成人编程教育则有更强烈的目标指引即就业。所以我觉得也许编程教育也会是 YodaOS 及其周边生态的一次机会，如果能将 YodaOS 生态引入课堂，从技术源头切实降低嵌入式开发的学习、实践和工程化门槛，再将这个优势导入市场，这势必也会成为 YodaOS 推广的基础。 3、这次我给的方案里面，设备端部分的开发因为业务流程不多所以难度较低，且他们自己也有一些积累，但 IoT 服务端的开发他们是没有任何经验的，在沟通方案的过程中对方也要求我在给方案的同时也要做好技术选型，最好是能找到满足大部分功能的开源项目并基于此进行二次开发，以此提高产品成型速度降低成本（但其实我觉得这个是困难的）。因此我也在 GitHub 上搜索过，也可能是我搜索的方式不对，目前没有找到很合适的开源项目。传统 Web 服务端开发经过长期的发展已经能为开发、测试等流程提供了大量的平台、框架、工具、规范和标准，但这在 IoT 领域还是比较缺乏。 4、关于谈判能力。从结果看这次合作其实并不成功，因此这里也只是简单叙述了整体设计思路和架构方案。不成功的原因我认为一部分在于对方其实也没有太大的决心来做这件事，并且团队还没完全组建，对于业务也缺乏深入思考和规划，且在沟通的过程中也没有表现出太多的诚意与决心。另一方面还归咎于我自身的谈判技巧与沟通方式，也许也是我自身急于求成且当时也确实面临找工作的压力，因此最终没有深入规划整件事情并与对方持续合作。但总体来说获益匪浅。","permalink":"https://txiaozhe.github.io/2020/02/29/IoT-for-edu/","photos":[]},{"tags":[{"name":"Job","slug":"Job","permalink":"https://txiaozhe.github.io/tags/Job/"},{"name":"Live","slug":"Live","permalink":"https://txiaozhe.github.io/tags/Live/"},{"name":"BigData","slug":"BigData","permalink":"https://txiaozhe.github.io/tags/BigData/"}],"title":"复盘1：直播大数据采集（二期）","date":"2019/12/29","text":"上一篇文章《直播大数据采集（一期）》（以下简称《一期》）复盘了之前做过的一个采集直播大数据的项目，其中介绍了项目相关的业务和技术实现始末，也描述了当时碰到的问题以及采用的解决方案，但由于涉及到太多细节导致篇幅过长，且当时项目迭代也是分为两期来做的，所以将整个项目分为两篇文章来描述。本文即承接上文介绍当时由于业务需求和技术迭代所做的二期改造过程。 一期项目中已对初始的业务需求进行了实现，如直播大数据采集、数据分析、平台展示等。当时整个采集系统采集的直播间数量峰值为 10 万个，集群规模为 40 节点，也就是高峰时平均每节点要承担 2500 个直播间的采集和数据清洗任务，而每天流过整个系统的总流量为 400 ~ 600 G，集群采用 Ansible 进行统一部署，使用 Alinode 和 Grafana 进行监控和管理。且后期使用爬虫代理对风控较严格的平台进行采集，使得数据流趋于稳定，基本能满足业务需求。于是开始着手准备二期升级和迭代。 工程上的任何一次迭代都应该基于现实业务或解决某个问题，此次迭代也正由于需求方提出了新的需求以及我们也希望通过这次迭代能用更好的方式解决一期项目中遇到的问题。整理当时接到的新需求以及待解决的问题如下： ”原始数据“ 需求：当时部门内一个客户端团队（我当时处于数据团队）在设计客户端时，涉及到在客户端中展示主播在播时的弹幕和礼物，考虑到数据团队已经能采集到完整的直播流数据，因此他们希望能对接采集到的数据，而且最好是原始数据（但当时的架构中最终输出的是经过去平台化清洗的数据）。 优化本地数据清洗：一期项目中数据的去平台化清洗任务是在集群节点上进行的，其中涉及到大量的数据转换和计算，这加大了集群节点的负担。 关播后延迟关闭采集：在《一期》中已描述过，当一个直播间关播后，集群会自动关闭对该直播间的采集。延迟关闭也就是说当主播关播时，集群会延迟关闭对该直播间的采集。 调度服务的单点问题：集群服务都会关注的单点问题！ 架构重构设计基于以上提出的新需求以及问题，其中涉及到大量与数据相关的内容，这势必要对一期项目的架构进行重新设计。考虑到未来可能会有需求的扩展，且需要对整体系统进行解耦，决定采用应用普遍且适应性强的分层式设计的新架构方案。 如下图，整个系统维持原有采集架构不变，在这里分为数据层和应用层两大块。 数据层：即用于接收和处理所有数据。将原先分布于采集结点中的数据清洗过程独立出来进行重新设计，又将该过程分为三个阶段：原始数据、ETL（数据清洗）、大数据计算。 原始数据：从采集集群采集到的数据经过序列化后得到的初始数据，这些数据具有强烈的平台特色，因此这个阶段得到的数据在字段、类型、名称等方面存在很大差异。但某些特殊业务场景下也会需要该数据。 ETL：上述原始数据由于存在平台差异，因此无法进行统一计算和分析，因此在这一阶段需要对数据进行差异化抹平，即去平台化，以便后续进行统一计算和分析。 大数据计算：在该阶段根据特定业务需求对大数据进行分析计算得出结果，并提供给业务使用。 MQ（消息队列）：作为沟通原始数据、ETL 和大数据计算三个阶段的桥梁，集群获得原始数据后将数据直接发送至 MQ 中，而 ETL 和大数据计算阶段则可以根据需要对消息队列进行消费，且 ETL 阶段清洗后的数据也会被传至 MQ 中。 数据层负责对大数据的各种处理，一方面每一阶段都可以独立提供对外的响应接口，因此每一阶段得到的数据都能被单独应用，这使得未来业务具有更加强大的可扩展性，另一方面数据分为多个阶段来处理的方式与一期相比，系统达到了解耦的目的，且降低了集群节点的负担，各个阶段之间通过 MQ 交互，将整个过程异步化，本身相互依赖度也更加低，提高了数据处理效率的同时也降低了开发维护成本。 应用层：这一层主要是应用数据层提供的各种数据能力，包括但不限于各种业务服务、日志、存储相关部分，各个应用之间相互独立，也可单独部署。单独把数据应用独立出来可以增强整体系统的可扩展性，也极大地降低了基础设施与上层业务之间的耦合度。 技术实现根据上述架构设计方案，可以整理出各个部分需要做的开发工作。原始数据部分可以继承一期中的采集阶段，将节点采集到数据后所做的数据清洗操作移除，并直接将数据推送至消息队列。消息队列仍然采用阿里云 Loghub（虽然看上去不合理但是在当时 LogHub 属于白菜价而且后续大数据计算操作对接非常顺畅）。 大数据处理部分由于直接使用了阿里云的流计算和实时计算服务并由另一位同学单独负责，且该服务支持直接从 Loghub 中消费数据，处理起来除业务部分并不复杂，当时阿里云的技术支持也比较到位，所以不在此展开详述。 ETL 部分会比较复杂一些，且需要重新开发。梳理一下其中可能会碰到的问题： 数据量大：峰值 10 万直播间，每天 400 ~ 600G。 业务复杂：涉及到多个平台的不同种类数据，其中数据格式、字段名称含义、类型等都不一样，为最终抹平各平台间的差异需要做去平台化操作，并且市面上也找不到现成的清洗方案。 计算量大：一方面数据量本身较大，另一方面业务中会涉及到大量取值、转换、累计、求平均等数值计算操作，原有的 Node.js 方案（原本整体系统都是基于 Node.js 来实现）在这里可能并不适用。 基于上述问题，并在团队讨论后考虑在 ETL 的实现中放弃现有的 Node.js 体系，使用 Go 语言针对该特定场景开发一套数据清洗系统，且在 Go 服务和原有 Node.js 服务之间采用 RPC 通信。使用 Go 语言主要考虑因素如下： 性能：Go 语言作为一门编译型语言，虽然不如 C/C++ 那样效率超群，但对比 JavaScript 这类脚本语言还是绰绰有余的。且放弃现有 Node.js 体系的原因也主要是 Node.js 的本身设计因素决定了其并不适合用于大量 CPU 计算场景，与现有业务场景相悖，采用 Go 语言实现也能提高数值计算的效率。 学习成本低：作为业务工程化采用的技术方案，必然考虑的一个因素就是可持续维护，Go 语言的学习成本与 C/C++ 相比低太多，当项目人员流失时也能快速找到替补。 生态良好：Go 的语言生态持续完善，且市场上已有大量使用 Go 语言实现的优秀开源工具，如 Kubernetes、Docker。 采用新的架构方案并进行了相关优化的实现后，整体业务趋于平稳，架构中各数据层也能独立稳定地对外提供数据服务。将数据清洗操作从原有集群节点中拆分出来后也极大降低了节点负担，优化后的系统整体达到了架构设计预期的效果。 实现新需求上面提到，这次技术迭代的一个主要起因是业务层面有一些新的需求产生，这些需求一方面是业务本身需要，另一方面也是为了规避数据采集本身所带来的数据缺失或不准确问题。如当一个直播间关播时，采集系统延迟关闭对其的数据采集（正常情况下直播间关播时会立即停止采集）。 这么做的原因有两个： 一个是由于直播间开关播信号是根据从平台拉取的直播间列表计算得出的，但观察发现直播平台给出的列表有时候并不是准确的，这就会导致开关播的误判，从数据上看就会造成数据的不准确，延迟关播（也就是说主播关播时还继续采集一段时间，如 10 分钟，若 10 分钟后仍然没有开关播状态更新则说明真正关播了，则停止采集，否则继续采集）可以尽可能地规避平台列表错误所带来的数据不准确的问题。 另一个原因则是一些当红主播在关播后仍然会有一些观众发送弹幕和礼物，这一部分数据也是有价值的，延迟采集可以获得更多的有效数据。 具体实现方式为，使用 Redis 的 Sorted Set（有序集合）特性。构建一个主播 id 和其最新在线时间关联的数据，并将其放入一个 Sorted Set，以主播最新在线时间为排序依据。主播的最新在线时间会定时更新（正常为 1 分钟），并在在线时间更新时同步更新 Sorted Set 中对应主播的最新在线时间，这样就实现了一个如下图所示的时间轴： 正常情况下，由于集合中的主播最新在线时间是定时更新的，因此正常开播的主播都会集中在上图时间轴中的等待区，假设某主播的最新在线时间同步异常，则导致集合中的时间无法更新，但此时时间依然再往前推移，最终在超过规定的最大等待时间（在这里假设 10 分钟）后，该主播会进入上图时间轴的待关闭区。在这样的设定下，所有主播都会分布在整个时间轴的两个分区内。 此时，调度中心要做的事情就变得更加简单，只需要定时去 Sorted Set 中按照时间区间取出要继续采集的直播间和需要停止采集的直播间并做出相关操作即可。 单点问题单点问题是分布式服务都会遇到的问题，在本系统中也不例外。采集系统中可能会碰到单点问题的部分有：直播间列表拉取服务、调度中心服务、MySQL 数据库以及 Redis 缓存。直播间列表拉取服务用于定时拉取各个平台直播间列表，从架构上看并不属于集群范畴，所以在此不做介绍。MySQL 数据库和 Redis 缓存也不属于本文的主要讨论范围，因此也不做详细解说。接下来就主要讨论一下调度中心服务的单点问题。 引用一下《一期》中的架构设计图： 从架构设计中可以看出，调度中心主要负责集群控制、任务分配、任务回收的工作。由于调度中心是由一台独立的服务器单独部署的，所以可以分析一下当调度中心挂机后可能会出现的问题。 集群状态无法管控：调度中心会与集群中每一个节点进行长连接，并实时获取每个节点的负载。假如调度中心挂机会导致集群失控，节点数、负载等信息无法获知。 新任务无法分配：调度中心一方面掌控集群中所有节点的负载等相关信息，另一方面接受来自任务源的采集任务，并按照节点负载将任务均匀分配给每一个节点，若调度中心挂机则会导致新任务无法开启采集。 现有任务状态失控：当集群中某节点挂机或某节点上的某任务失败，调度中心会将该节点上的所有任务或某个失败任务进行回收，并在集群中均匀分配给健康的节点。一旦调度中心挂机则会导致任何失败的任务都无法回收再分配。 要解决上述问题，考虑采用主备的方式。 初步方案本系统中主备方案的设计最大的问题即是如何确保任务的正确分配与回收。调度中心一方面需要从唯一的任务源获取到任务，另一方面还要准确地在集群中每一个节点之间均匀分配和回收所有任务。因此初步的主备方案必然需要考虑到任务的一致性。 初步的设计方案如图： 为了更好地管理所有任务，在调度中心节点和集群中间加一层用于存储所有节点状态和负载并定时更新的的节点池（用 Redis 实现，简单起见假设缓存节点稳定性远高于服务），而在任务源和节点池之间设置两个调度中心，任务源会根据调度中心的状态将任务分配给健康的节点，同时调度中心也会向下将任务分配。 后续上述解决节点单点问题的初步方案在后期并没有继续进行讨论并实施，系统的单点问题也没有当做主要问题去解决。主要原因有两个： 系统真正的稳定性瓶颈在于爬虫风控：每一个系统都有其性能和稳定性的瓶颈，在这里系统的稳定性瓶颈并不在于单点问题或系统某部分的不稳定因素（虽然调度中心甚至数据库都有挂机的可能），而在于采集的部分平台对爬虫有着很严格的封锁机制，导致数据断流或错误，最终严重影响业务。因此当时我自己包括团队也将主要精力用于应对平台的反封锁。 尽可能规避不稳定因素：当时也是采取了一些措施来应对系统的不稳定因素（如单点问题）的，如监控。另外也对任务分配和回收机制做了优化，使得即使调度中心挂机了，现有的任务也不会受影响，从而最大程度上以最小的代价规避单点问题所带来的业务差错。 尽管当时业务上并没有深入讨论关于单点问题的解决方案，但对于技术工程上来说这仍然是一个值得思考与讨论的问题。上述初步解决方案也存在很多问题与不合理的地方，如果读者有任何见解，欢迎在下方留言区留言讨论。 问题与讨论在后来的一些面试或聊天中，有过多次与同行聊起这个项目的经历，其中也碰到过一些比较有意思的问题，现整理问题以及我的回答如下： 用 LogHub 做消息队列？疯了吧？ 答：当时考虑了两方面因素，其一是成本，那个时候 LogHub 真的属于白菜价。其二阿里云方面也确实支持将 LogHub 作为消息队列使用，服务也能较容易的对其数据进行消费，且 LogHub 与后续需要对接的流计算和实时计算在阿里云是天生支持的。 为什么不用一台很强大的服务器并在其中使用 Docker 部署采集结点？这样不是更容易管理吗？ 答：这个业务场景下其实不难看出最缺失的资源并不是计算资源，而是 IP，为了规避平台的封锁我们也曾费尽心机最终采用爬虫代理实时更新代理 IP 才勉强支持业务。而对于在一台服务器上部署 Docker，这看上去很好，但其实最终也是不利于横向扩展的。 结语本文承接《一期》，继续探讨了整个采集系统的后期迭代和业务升级。相对于《一期》，本文的叙述更加零散，但我也基本还原了当时场景下切切实实碰到过的技术和业务问题的细节。且这个项目是在 2017年 ~ 2018年年中期间实现并迭代的，里面涉及的很多技术实现方式放在现在的场景下可能已经有了更好的替代方案，所以对于本文涉及到的各种方案与观点，读者如果有任何建议或好的想法，欢迎在下方留言区反馈或展开讨论，非常感谢 :)","permalink":"https://txiaozhe.github.io/2019/12/29/live-data-fetch02/","photos":[]},{"tags":[{"name":"Job","slug":"Job","permalink":"https://txiaozhe.github.io/tags/Job/"},{"name":"Live","slug":"Live","permalink":"https://txiaozhe.github.io/tags/Live/"},{"name":"BigData","slug":"BigData","permalink":"https://txiaozhe.github.io/tags/BigData/"}],"title":"复盘1：直播大数据采集（一期）","date":"2019/12/15","text":"这是2017年10月到2018年10月在全民直播期间的一个项目，因为在直播公司的缘故，所以会涉及很多直播相关的业务。当时有几家做的比较好的直播平台，比如斗鱼、虎牙、熊猫、战旗、全民等，直播内容都以游戏、才艺表演为主，直播受众广，每天产生的数据流量巨大，公司为此启动一个新项目，采集全平台直播数据，并经大数据技术清洗统计后为直播行业提供数据化运营解决方案。 加入全民直播的时候正值刚毕业不久，从河北来到杭州，机缘巧合就入职了全民，接手了这一项目，因为当时负责项目开发的工程师即将离职，因此我也算紧急受命。对那时候的我来说，这个项目算是相对难度最高的，为什么这样说呢？首先因为我本身并不是计算机科班出身，再加上在学校自学的经历，虽也接触过不少的技术，但都不深入，所以当初次接触到这种成体系的项目时就显得有些局促了。当然，项目本身也算是难度比较大的，由于是后期接手的缘故，所以也就没有参与初期技术方案的设计，但其中的细节还是值得考虑的。本文即是复盘当时项目的业务及技术细节，结合接手项目后及二期改进所做的工作，对当时碰到的问题及技术方案设计进行整理和思考。 简单介绍一下业务如果你看过游戏直播（如果没看过现在可以打开看看，比如斗鱼、虎牙）就会比较熟悉，当打开一些热门网红的直播主页时会看到很多内容，首先是源源不断刷过整个屏幕的弹幕，还有一些粉丝送给主播的礼物（比如火箭），这些都算是动态数据，而且从全网来看数据量巨大。其次还有很多相对静态的内容，比如主播名称、热度、关注度等相关信息。对于做直播业务的公司来说，这当然是有价值的。因此我们要做的事情就是把这些动态和静态的数据源源不断地从网络上抓取下来，并通过一些大数据手段进行清洗和计算，最后得到一个全网主播的动态信息汇总平台，并向行业内相关人士或机构提供大数据咨询服务。 面临的问题从技术层面思考这个事情，其实简单来说我们要做的就是通过一些手段把上面说的各种静态和动态数据从各个直播平台上抓取下来（说白了就是爬虫），然后通过一个大数据清洗和计算流程汇总得到业务所需的形态，最后通过网页或 app 的形式把数据展示给用户。 业务目标清楚了，接下来从技术角度梳理一下做这个事情可能会碰到什么问题： 直播平台众多，各平台无兼容性：当时正值娱乐直播业务的红海期，各种直播平台相互竞争，首期决定采集的平台有斗鱼、虎牙、龙珠、战旗、触手、熊猫、全民。 涉及数据类别有多种，协议层适配和数据清洗会很复杂：首期决定采集的直播数据有弹幕、礼物、主播个人信息、主播热度及关注度 可能会遭到平台方的封锁：毕竟是爬虫，你懂的（不过不像现在，当时还没有这么严重的法律风险）。 从直观上看数据量可能会很大：最终从事实上来看确实很大，数据的采集、计算、存储、读取都需要考虑这方面因素。 技术选型及解决方案语言：Node.js / Go（二期升级时采用） 数据库、缓存及静态存储：MySQL、Redis、阿里云 OSS 数据搜索服务：Elasticsearch 服务器：阿里云 ECS 流数据池子：阿里云日志服务 前后端：Express / Koa / Vue 冷数据存储：阿里云 ODPS 服务器监控：Grafana / Alinode 部署方案：GitLab CI / Ansible 大数据清洗和计算：阿里云实时计算 平台及数据兼容层前面提到，首期业务决定采集斗鱼虎牙等7个平台的数据，深入看一下这几个平台的数据采集方式（由于当时有专门的团队已经做过相关工作，因此假设此时已经得到各个平台可用的 api 及接口访问权限，全民属于自有平台，接口信息也可看作已知）会发现每个平台都是不一样的，从接口协议层面看，因数据类别不同涉及到的协议有 TCP、WebSocket 以及 Http，动态数据如弹幕和礼物因为实时性比较强所以一般都是用 TCP 和 WebSocket 传输，当然也有比较奇葩的用 Http 的（比如触手）。静态数据如主播个人信息、关注度等则基本都是 Http 接口，当然也有不提供特定接口而直接从后端渲染的，不过本质上没有太大区别，只是后期处理上会稍显繁琐。 为了解决上述问题，比较通用的做法是在所有平台之上建立兼容层，将需要采集的数据分为 弹幕/礼物、主播信息、热度、关注数四大类，并抽象出其中的接口及事件。 如对于弹幕/礼物数据的采集模块来说会抽象出如下接口和事件： init：按平台需求进行鉴权、Socket 连接及开启数据监听（针对 TCP 和 WebSocket）、初始化轮询请求（针对Http）以及请求一些附加的平台数据操作。 destroy：断开连接停止采集。 connect 事件：监听连接事件。 data 事件：接收请求到的数据，并进行相应的后续处理。 error 事件：等待超时或出现错误，则停止采集或进行重连。 close 事件：正常关闭操作。 在兼容层的上层，则按照采集到的数据的不同格式及类型建立 ETL 层对数据进行清洗得到平台通用的数据格式，架构示意图如下： 对于主播信息、热度、关注数类别的数据处理方式也是类似，针对平台差异抽象出不同平台的接口共性，并在使用时按平台调用。 采集集群如果打开一些热门网红的直播间会发现在其直播期间，屏幕上会飘过海量的弹幕和礼物，从全平台来看，这些数据的量是非常大的，在项目维护期间我也曾做过粗略的统计，发现每天流过系统的数据量达到 400 - 600G，也就是说每天采集到的数据能装满一个 500G 的硬盘，这还只是清洗过后的，且不计图片、头像等数据，如果按照清洗前的量将大大超出这个值。要实现将这个量级的数据实时地从网络上抓取下来并集中清洗，势必需要多台服务器配合组成集群，将负载分配到每一个节点，并能根据采集量动态伸缩集群容量，达到业务和成本的平衡。 集群架构设计如下图： 任务系统要采用集群化采集方案，则必然设计一套任务系统，将采集任务细化、标准化。这里还会涉及到另一个数据需求，即直播间开关播状态。因为当时并没有获取直播间状态的方法，因此采用列表对比的方式获得相对准确的直播间开关播状态，原理简单来说就是定时拉取平台的直播间列表并存储到 DB 中，等下一次再拿到列表时与 DB 中的列表对比得出开关播状态。如 DB 中已有 A、B、C 三个直播间状态为开播，下一次拿到的列表为 A、B ，则此时判定 C 直播间关播，以此类推。开关播状态除了本身是数据需求的一部分以外，还是采集节点采集数据与否的依据，因为观察发现，当主播关播时，直播间将没有或只有少量弹幕礼物数据刷过，这一部分数据可以忽略不计，为此当主播关播时关闭采集可以节省成本。 使用一台单独的服务器拉取各个平台主播列表作为任务源，拉取时间间隔为 1 分钟，主播列表中会包含主播详细信息并将该信息存到一张单独的表中。拉取到的列表按不同平台分批发送至调度中心，由调度中心来完成直播间状态的比对，并将该信息更新到 DB 中。 调度中心调度中心会负责两方面的任务，一个是上面提到的，接受来自任务源的任务队列，并与 DB 中已有的任务进行比对得出需要更新的直播间状态。另一个则是分配任务。 采集集群会在启动时与调度中心取得长连接，采集节点会告知本机的局域网 IP 地址（集群中所有节点都在同一个局域网内），并将本机采集负载（采集任务数）通过 RPC 接口的方式暴露给调度中心，保持长连接意味着采集节点的状态变化可以实时地被调度中心感知到，调度中心依据此维护一个可用的采集节点列表（即 IP 列表），并能通过 RPC 机制实时地获取每个节点的负载。当调度中心收到来自任务源的任务列表时会比对得出所有需要更新采集状态（开启或停止采集）的任务，如遇到需要新开采集的任务时，会在可用的采集节点列表中选取一个负载最小的节点，将该节点 IP 与该任务绑定，赋予任务状态为 ACCEPT，表示该任务为新接收的任务，并将该任务存至任务列表。同时，若调度中心感知到某节点出现异常，比如断开连接，则调度中心会将任务列表中标记给该节点 IP 的所有任务取出，重复上述步骤，选取一个负载最小的节点，将该任务分配给该节点，若出现问题的是某任务，则调度中心会为其重新分配一个节点，该任务会被该节点发现并重新开启采集。这样一来，所有任务将在整个采集集群中动态平均分配，并在节点异常时及时回收任务再分配，以此平衡所有节点的负载，并将节点异常带来的数据损失降到最低。 集群采集集群的工作即按平台差异以不同的方式从各个直播平台源源不断地拉取数据，集群中每一个节点都是等价的，集群规模也可以动态伸缩。集群节点服务主要以两部分组成：Manager（任务管理器）和 Bee（采集器）。Manager 是集群节点的主体，一方面在节点启动时，Manager 会与调度中心连接并实时同步 IP 信息和负载水平，另一方面，因调度中心已实时地将各个需要开启和关闭的任务同步至任务列表中，Manager 会定时到任务列表中领取与本机 IP 相匹配的任务进行相关操作，如开启或关闭采集。采集的主体即 Bee（命名取自小蜜蜂采集花蜜），当 Manager 拿到一个需要开启采集的任务时，会初始化一个 Bee 实例，Bee 初始化时会按照指定平台调用实现了特定接口的客户端与平台方取得连接，并将列表中任务状态改为 RUNNING，Bee 会接受来自平台的数据流，并调用特定的方法对数据流进行解析、计算、清洗，最终以统一的格式写入阿里云日志服务。也就是说，一个采集结点中只有一个 Manager，但该 Manager 会管理多个 Bee 实例。当某个 Bee 实例出现异常，比如与平台断开连接，则 Bee 会停止采集并将该任务标记为 FAILED，后续该任务会被调度中心发现并重新分配。同理，当 Manager 拿到一个待关闭任务时，则将该任务标记为 CLOES，后续该任务会进入关闭流程，关闭与平台的连接，并从任务列表中清除。 初期集群规模为 40 台阿里云 ECS 服务器，并通过 Ansible 统一部署与管理。每个集群上的任务数和资源占用水平都可以通过 Grafana 查看。从最终结果看来，全平台高峰期同时开播的直播间最高为 10 万个，也就是峰值任务约为 2500 个/台，LogHub 流数据为 400 - 600 G/天，这都在系统各个部件的承受范围内。且所有服务器都通过 Alinode 进行实时监控。 规避风控前面已经提到过，该采集任务可能会碰到平台封锁的问题，事实上也是如此，且在业务后期平台封锁问题已成为整个服务的最大瓶颈。平台的封锁主要集中在任务源处，若直播平台封锁任务列表的拉取，会导致采集任务无法更新，最终导致数据与实际数据差距巨大，造成业务上数据不可信。因此解决该问题一直是最重要的任务。当时采取了以下几种方式： 规避平台风控规则：平台的封锁规则一般都和拉取频率有关，若拉取频率超过平台规定的阈值，会导致封锁。因此在拉取列表时尽量规避，该方法成本低，虽造成任务更新不及时，但也算保全了一部分数据，总体来看效果一般。 通过 CDN 节点拉取数据：直播平台一般都会有大量 CDN 节点，因此可以借助 CDN 进行数据拉取。但实施后发现 CDN 节点部署位置较分散，甚至有很多部署在国外，虽说这样做规避了一部分封锁的风险，但由于拉取速度太慢，总体效果不好，最终放弃该方案。 代理：终极解决方案，通过专门的爬虫代理服务器对目标平台进行请求，最终实现了较平稳的数据流输出。唯一的缺点是该方案成本较高。 计算本系统中采集到的所有数据，除了主播信息、主播关注度、图片等少量且静态的数据存储在 MySQL 和 OSS 以外，其他动态数据都被存至阿里云 LogHub 日志服务中，主要原因是 LogHub 成本极低，且能在阿里云平台上动态查询检索数据，又由于 LogHub 与阿里云实时计算已实现了无缝对接，所以将其作为消息队列使用，业务过程中曾经考虑使用 Kafka 作为消息队列，但由于部署成本较高，且若使用 Kafka，则后续实时计算和流计算都需考虑自行部署（当时是这样），因此一直坚持使用 LogHub。 由于大数据计算部分是由另外一名同学专门负责的，因此我当时也没有参与相关操作，这里不再赘述。由于经过计算后的数据量仍然极大，以此该同学已考虑到将所有结果数据按照时间（大部分数据区分到月份，部分数据区分到日期）分表存放，以便于后续服务读取。 服务业务的最终目标是将上述采集、清洗计算得出的数据以数据平台的方式展示给用户，因此最终的产品形态是一个网页，主要由 Koa + Vue 实现，其中涉及到数据的读取，由于数据量较大，因此前期会将一部分数据按照热度进行缓存以提高读取效率。因该服务也是另一位同学专门负责，其中涉及的技术主要有 Web 服务、用户系统、数据库 CRUD、API 接口等，与一般 Web 服务没有太大差异，因此在此不再赘述。 还没完由于业务上的需求以及技术迭代，该项目进行了二期改造。其中会涉及到更多的技术细节，如调度中心的单点问题、任务分配机制有没有更好的方案、如何提高本地数据清洗效率等等。本文即较完整地阐述了直播大数据采集一期项目的技术实现细节，原本打算将二期也一起讲述，但由于涉及细节太多，目前篇幅已过长，因此决定将二期内容放到下一篇文章详细讲述。 本人一直坚持，技术没有好坏。而技术也一定是与业务的平衡和取舍。如有不明确或错误的地方欢迎留言或指出~不喜勿喷 :)","permalink":"https://txiaozhe.github.io/2019/12/15/live-data-fetch01/","photos":[]},{"tags":[{"name":"IoT","slug":"IoT","permalink":"https://txiaozhe.github.io/tags/IoT/"},{"name":"JavaScript","slug":"JavaScript","permalink":"https://txiaozhe.github.io/tags/JavaScript/"},{"name":"JerryScript","slug":"JerryScript","permalink":"https://txiaozhe.github.io/tags/JerryScript/"}],"title":"JavaScript in IoT","date":"2019/12/13","text":"今天分享的内容是 “JavaScript in IoT”，在低端设备上运行 JavaScript，这与我上一段工作经历有关，之前我在一家做语音交互和 IoT 的公司，负责 IoT 设备端服务的基础架构，简单来说就是运行在 IoT 设备上的一个服务，与 IoT 云端交互用的。当时我用的 IoT 设备主要是几款智能音箱，上面有搭载有嵌入式开发板，系统资源的话内存基本都在100MB 左右，这相对我们日常开发用的电脑或服务器来说可以算是捉襟见肘的，我负责的内容就是用 js 语言在这个板子上面做一个与云端交互的模块，那这种低端设备上如果运行日常用的 Node.js 肯定是跑不动的，所以我们为了实现在 IoT 设备运行 js 并用 js 写程序，特地开发了一套针对 IoT 场景的 js 运行时，叫 ShadowNode。对我来说最开始的时候我只是这个项目里面的一个贡献者，后面跟团队接触多了，也就逐渐地被吸引以至于最后直接加入团队，后面就用这个工具进行 IoT 的研发，慢慢地也对整个体系有了更多的了解。 IoT The Internet of Things (IoT) is a system of interrelated computing devices, mechanical and digital machines, objects, animals or people that are provided with unique identifiers (UIDs) and the ability to transfer data over a network without requiring human-to-human or human-to-computer interaction 什么是 IoT， 全称 Internet of things，也就是物联网。这是 wiki 上对 IoT 的解释，IoT 是一种由具有唯一 id 的计算设备、机械、数字设备、物体、动物或人等关联起来的系统，并且可以通过网络传输数据，无需人与人或人与计算机交互，也就是所谓的万物互联。但目前为止我们日常所碰到的 IoT 设备见得比较多的还是各种灯、音响，比如米家有各种设备可以连入网络，我们之前就有自研的智能音箱，可以连接各种三方设备，并可以通过语音或手机控制。 为什么是 JavaScript首先对于程序员，肯定要考虑如何对 IoT 进行编程，或者说在嵌入式设备上写程序，我们可能比较了解的是用 c 或 C++ 语言进行编程 ，因为 IoT 设备中充斥着大量低端设备，这里说的低端设备指的是比如各种嵌入式芯片，RAM 或 ROM 或 flash 容量非常小，我们所知道的树莓派已经算是很高端的设备了，通常内存都在2G 以上，比如我们以前用的智能音箱上的内存基本都在100M左右，因此在这种设备上写程序，c/c++ 基本是标配。 但我们今天要讲的是用 JavaScript 在这种低端设备上编程。大家可能觉得我们疯了，因为都知道JavaScript是一种脚本语言，一直以来主要在前端里面用，后来被引用至服务器端也就是 Node.js。当时对我们来说最现实的需求就是，最开始我们的 IoT 服务都是用 js 写的，而且运行在比较高端的设备上，后来引入低端设备的时候发现如果不做底层的优化，那所有的业务都得重写。JavaScript作为一种脚本语言是解释执行的，其性能堪忧，而且也不是世界上最好的语言，但我们也知道，JavaScript拥有非常完善的社区生态和庞大的开发者群体，这是一个非常大的优势，其实用 C/C++ 编程相对来说门槛还是挺高的，但试想一下，如果一个前端开发者，只会 js 语言，原本只会写前端页面，但是现在能在简单学习了 IoT 设备相关 api 后就能动手开发嵌入式程序，想想是不是很酷，其实这也是我们的初衷，也就是利用 js 的生态和社区基础，降低嵌入式开发的门槛并助推推广 IoT 的发展。至于性能什么的，这是我们需要考虑的！ 而且我们也确实在低端设备上去运行 js 了，那我们是怎么做到的呢？ Node.js讲到JavaScript，必然要提到 Node.js，而且今天的主要内容也会跟 Node.js 有关。我们知道 Node.js 是在服务器端运行JavaScript的环境，类似于虚拟机。 V8/libuv是构成 Node.js 的两大核心组件，V8 原本是chrome 的 js 引擎，后来被引用到 Node.js 中，为 js 语言提供了解析和运行的环境，libuv 则是我们常说的 Node.js 异步非阻塞的来源，这里面也用到了很多系统级的api和资源。还有一些三方库用来为系统提供一些功能，比如openssl，crypto、zlib等等。 同样，在嵌入式设备上运行也可以采取类似的架构，因为本身也都是linux，比如需要一个可以在低端设备上运行的 js 解释和执行环境，然后也需要一些额外的支持用来提供异步i/o以及各种上面提到的加解密、网络通信等等操作 后来我们就找到了 JerryScript JerryScript JerryScript is the lightweight JavaScript engine intended to run on a very constrained devices such as microcontrollers: • Only few kilobytes of RAM available to the engine (&lt;64 KB RAM) • Constrained ROM space for the code of the engine (&lt;200 KB ROM) The engine supports on-device compilation, execution and provides access to peripherals from JavaScript. JerryScript 是一款由三星研发的用于 IoT 设备的 js 虚拟机 这是jerry 官网首页的一句话简介：JerryScript 是一个为 IoT 而开发的轻量级 JavaScript 引擎，可以运行在资源十分受限的设备上，支持在设备上解释、执行 JavaScript 以及对外围设备的访问，内存低于64KB，rom低于200KB，可以说对资源很苛刻了。 这个表展示了各种层次的设备的软硬件指标，JerryScript 就是针对下述 Low-end 也就是低端设备开发的。 Low-end Medium-end Smart phone RAM / ROM Tens of kb ~ 4MB Hundreds of MB GB+ Processor 1 Core 1 – 4 Core 4 Core+ OS RTOS Linux Android / iOS JerryScript 也可以看作是对 EcmaScript 标准的一个实现，目前支持到 es5的标准 Jerry 之所以能在低端设备上运行，因为其采用了非常紧凑的内存布局设计，对源码解释、运行过程、对象属性、值表示以及函数操作都做了针对节省内存的优化 比如：v8里面对 js 源码的解析会经过源码 –&gt; ast（抽象语法树）–&gt; 字节码，而 jerry 直接把 ast 那一步省略了，直接从源码解释成字节码。另外jerry还对字节码快照进行了优化，可以直接执行快照，甚至可以把快照存到rom里并直接从 rom 里执行快照，这样节省了源码解析的内存消耗与性能成本。 另外 jerry 对各种类型和值表示的内存布局也设计得相当紧凑，这极大地节省了内存，当然，极致的优化也会带来一些副作用，比如代码的执行效率会降低。 具体的就先不展开了，感兴趣的话大家可以去jerry官网看，感兴趣的同学也可以把源码 down 下来，本地编译一下，或者也可以按照文档的说明用这个引擎把你的 js 代码嵌到 C 代码里运行，不过直接在 mac 上编译会碰到一些问题，在此我也准备了一个 docker 容器，我在里面已经准备好了所有编译 Jerry 所需的环境，并发布到了公共的 docker hub，感兴趣的同学可以 pull 下来试一试。 IoT.js前面说了，只有一个 js 环境并不能搞定一切，一个裸的 js 虚拟机还是太局限了，因此还需要一些额外的支持来提供完善的环境，幸好三星也同样做了这样的支持。为此三星还开发出了 Libtuv。 Libtuv，是对标 Node.js 所用的 libuv 的嵌入式版本，也是三星开发，为整个运行的环境中提供异步I/O的能力。而 IoT.js，就是一个完整的能在嵌入式设备上运行的 js 运行时， Node.js 支持的特性它也基本支持，比如异步I/O，事件循环，以及各种原生的api。 其实整个架构体系和我们刚刚看到的 Node.js 是差不多的，只不过底层支撑的模块不一样，同时，为了能更好地运行在 IoT 环境里，IoT.js 也根据嵌入式设备的场景做了一些额外的支持，比如 mqtt，还有一些对嵌入式设备的操作支持。 讲到这里，好像没什么事可做了，因为三星已经把该做的都做了，IoT.js 做的支持也足够，什么异步 i/o， IoT 适配都做了，对内存的优化也做到了几十k的变态级别，但这真的就是我们想要的吗？ 我们看看 IoT.js 有什么问题？ 为了把内存控制在几十k的级别，IoT.js 可谓是费尽心机，这也导致了 IoT.js 不支持很多好用的特性，比如不支持类，promise，甚至不支持 debug，出错的时候无法输出完整的错误栈，这就很头疼了。不过，当时我们业务上用的设备也没那么苛刻，基本都是内存在 100MB 左右的中端设备，而且也为了顺应社区和生态的需求，我们也希望我们用的运行时能支持更多的特性，也能更加容易使用，所以我们就在 IoT.js 的基础上开发了 ShadowNode。 ShadowNodeShadowNode 是基于 IoT.js 一个运行时，只不过面向的目标设备不一样，IoT.js 面向极低端的设备，而 ShadowNode 则是面向中端设备，因此两者并不冲突。我们当时的工作主要有几个，一个是对于一些实用特性的支持，比如错误栈、更完善的 js 语言特性等，还有一个就是支持更多的 Node.js api 以及社区的构建。 ShadowNode 的原生支持目前 ShadowNode 原生支持的特性有 Class，Promise，以及 debug 的错误栈输出，N-API等等，以及更完善的兼容 Node.js 的 api，不过目前一些特性在 JerryScript 中也逐渐被支持了，生态总是越来越完善。 mqtt &amp; dbusmqtt 其实是一个面向 IoT 场景的通信协议，基于 TCP，同样的，协议的设计也十分精简和“节约”，有点类似于我们平常在做 TCP 通信的时候自己定义的封包规则，只不过里面还定义了很多校验数据的规则，总体来说也是为 IoT 特殊场景而优化的。至于 D-Bus，可能做过 Linux 开发的同学会更加熟悉，这是一种高效的 IPC 机制，感兴趣的同学可以自行查阅资料。 支持的平台目前 ShadowNode 支持以下平台： Linux / (Docker) MacOS Raspberry Pi Kamino18 / (Amlogic/a113) / Hi3561 NuttX / TizenRT ShadowNode 在 Linux 和 MacOS 中能被友好地支持（不过在 mac 上编译会碰到一些问题，比如 dbus，可以参考 issues 解决），目前 windows 还不支持。感兴趣的同学也可以尝试在 docker 容器中试着编译运行，我之前尝试过，也碰到过一些问题。Raspberry Pi 也是支持的，不过大多数树莓派属于高端设备了，使用 ShadowNode 的意义并不大。Kamino18 / (Amlogic/a113) / Hi3561 是我之前在工作中用到过的三款开发板，其中 Kamino18 是rokid 自研的，Amlogic/a113 是晶晨半导体的，Hi3561来自华为海思。至于 NuttX / TizenRT，其实我也不太懂，是 ShadowNode 主页看来的，貌似是两款 rtos，感兴趣的同学可以自行搜索相关资料。 NPM目前对于 ShadowNode 来说，原生的 npm 还不支持，其实支持起来是不难的，而且我们当时的期望是兼容整个 Node.js 体系的，只不过这里面有一些现实原因，比如兼容性、性能等等，这也是我一直认为比较遗憾的地方。 我们在系统定义了一个全局的 node_modules，使运行时默认寻址，这样就能减少包导入的消耗。因为我们还是希望以此去推动社区发展的，并也希望能通过社区助力整个生态的成长，因此包管理机制怎么也得有一个，目前完全开放的 npm 使得任何人都可以随时写一个 Node.js 包发到 npm 平台上，这也就会造成包管理混乱、代码质量不可控等问题。我当时所设想的是一种半私有的包管理机制，在兼容 Node.js 端和设备端的同时，鼓励开发者把现有的 Node.js 包改造成能在设备上良好运行的样子，而且可以发到我们的平台上，当然，我们会加强审核，比如需要通过我们的性能测试以及代码 review。 硬件接口ShadowNode 也同样支持一些硬件接口，比如 ADC/BLE 等等，这个的话有兴趣的同学可以自行看资料。 社区和商业化有了工具，必然是要做一些事情的，除了当时我负责的 IoT 设备端服务外，我们还基于 js 和 Linux 打造了一款面向 IoT、智能设备以及语音交互的操作系统 YodaOS，并定义了一套语音交互应用开发的范式VUI和标准，而且后面我们也期望开发我们自己的 js rtos – rt-node，关于这些内容这里就不再做详细介绍了，原因的话一方面这几块内容我并没有直接参与，所以对里面一些细节也不很了解，另一方面 YodaOS 相关的内容与当时公司的业务太紧密相关，而且也区分商业版和社区版，所以这里也不适合详细介绍，感兴趣的同学可以自行去搜索相关内容。 相关链接： IoT wikipedia JerryScript JerryScript GitHub JerryScript Env by Docker IoT.js IoT.js GitHub ShadowNode GitHub YodaOS GitHub yoda.js GitHub rt-node GitHub Thanks :) @eshine @yorkie @lolbig","permalink":"https://txiaozhe.github.io/2019/12/13/javascript-in-iot/","photos":["/images/javascript-in-iot.jpg"]},{"tags":[{"name":"Life","slug":"Life","permalink":"https://txiaozhe.github.io/tags/Life/"},{"name":"Job","slug":"Job","permalink":"https://txiaozhe.github.io/tags/Job/"}],"title":"写在 2019 的结尾","date":"2019/12/05","text":"2019 眼看着就要过去了，匆匆忙忙一年又一年，回望即将过去的2019，失落地发现好像这一年充满了遗憾，但总的来说过去的一年还是有所收获的！ 两年前的十月，我离开了待了四年多的大学以及让人爱不起来也恨不起来的那个城市，带着一些不舍与无奈、也有信心和期待，还有20本书和债务，来到杭州，入职了一家看上去挺有意思的公司。时间可过得真快呐，一年前的十月，我就离开了那家现在看起来就是在压榨我的公司，当然，离开的原因并不是网上流传的那种95后一言不合就炒了老板，个中缘由，网上查查就知道了。 那个时候我总告诉自己无论在哪里，一定要心怀感恩，因为这样我才能在各种环境中找到我存在的价值以及我得到的收获。当时正值区块链的概念炒得热火朝天，不过现在也不算冷。于是我顺势进了一家区块链公司。嗯那家公司挺不错的，哪怕现在看起来也很好，办公地点在环境极好的西溪湿地（虽然现在已经不在那了），而且福利也不错。正值年底，杭州的冬天还是挺冷的，但是不久以后，更冷的互联网裁员潮就来了。那段时间真的过得战战兢兢的，年初的时候去了一趟北京，回来发现变天了，身边的同事莫名其妙地离开，从那时开始感受到无奈，虽然最后并没有被波及到，但总是心有余悸的。现在回忆起那段时间来，算是职业生涯里最 “休闲” 的一段时间了，当然并不是因为偷懒，大环境使然吧！在西溪湿地工作的那半年里，每当吃完午饭，同事们就三三两两地在西溪湿地里面散步，半年下来，竟把大部分区域都转遍了，我拍了各种各样的照片与风光，戏称自己是西溪湿地景区管理员，也算是一个收获吧！但更大的收获还是来自于社区，在参与社区事务的过程中，给社区贡献过代码和建议，也开始尝试去推动一些事情的发展，并逐渐建立了自己的社区理念，最重要的是认识了很多非常优秀的朋友。在社区里行走就像登山，每个人都热爱登山，一个接一个地往上走，你停不下来的，因为总有人在你后面，不要挡住人家。 后来，我还是离开了，可能还是坐不住！ 现在回过头去看这即将过去的2019年，其中最重要的事情应该算入职 Rokid 吧！准确地说是加入了一个非常优秀的团队，开始与原先的社区伙伴朝夕相处，也接触了新的领域–IoT。不过讲真，在 Rokid 工作压力还是相当大的，倒没有996，主要是在那里你会看到所有人都在往前走，你走不动了也没事，会有人推着你。那段时间甚至开始轻微地掉头发，吓得我赶紧买了霸王防脱，小心地呵护随时可能上移的发际线。但也从那时候开始从全局角度思考问题，开始为代码的健壮性做努力，也开始逐渐放下躁动不安的心，把心思放在手上做的那件事情。在社区的一些想法一再搁浅的情况下，我开始反思我的那些所谓自己的理念，有大佬跟我说过一句话：你是一个工程师，归根结底是要解决问题的。 可是好景不长，在 Rokid 将将4个月，我又要离开了。这也是从业以来最舍不得的一次离职了！哪怕现在想起来也充满了落寞，也许曾经是有留下的机会的，但是看不清，哪怕现在也看不清。在离职后的一次偶然的事情中要去一趟 Rokid 楼内，发现原先能随意进出的门禁如今也要登记询问才能出入。看着留下的人庆祝五周年，心里五味杂陈！跟一同离职的小伙伴聊起 Rokid，我说要说对 Rokid 的感情，恐怕我还没这个资格，我想，真正舍不得的一定是团队了吧！ 匆匆忙忙来来去去，这次也来不及心怀感恩了，莫名其妙地开始找工作，本以为可以坦然地等待新机会的，在待业一个月并发了一次高烧后，心态终于绷不住了。来到新的环境，却见到老的同事，兜兜转转终究还是要走到一起的，只能尴尬地相视而笑，这个世界可真小。 相信一切都是最好的选择！ 2019年，没去什么地方，北京、上海、南京，都是有事才去的。去了绍兴、宁波，还行。 2019年，没有完整地看完过一本书，明年要补上。 2019年，花了大半积蓄给自己置办了一件大礼物，也受到过很多质疑，但我想，能用钱取悦自己其实是最简单的，剩下的就是去努力挣钱。 2019年，没有像想象中的那样找到女朋友，目测已经基本放弃，开始本着佛系找女朋友的心态面对各种亲人长辈朋友的亲切问候和热心关怀。 2019年，即将再见！ 2020年，有所期待也不过度期待！","permalink":"https://txiaozhe.github.io/2019/12/05/end-2019/","photos":[]},{"tags":[{"name":"JavaScript","slug":"JavaScript","permalink":"https://txiaozhe.github.io/tags/JavaScript/"},{"name":"JerryScript","slug":"JerryScript","permalink":"https://txiaozhe.github.io/tags/JerryScript/"}],"title":"JerryScript 学习笔记","date":"2019/11/18","text":"这是 JerryScript 官网的一段简介： 简单翻译一下： JerryScript 是一个为 IoT 而开发的轻量级 JavaScript 引擎，可以运行在资源十分受限的设备上，比如： RAM 低于 64KB 的设备 ROM 低于 200KB 的设备 该引擎支持在设备上解释、执行 JavaScript 以及对外围设备的访问。 说白了 JerryScript 和我们日常用的 Chrome 和 Node.js 中的 V8 是一回事，是一个引擎，只不过 JerryScript 能运行在更加低端的设备上，如嵌入式设备。我们知道，JavaScript 作为一个脚本语言有其先天的缺陷，如解释执行的效率低下以及臃肿的堆内存的占用，哪怕 V8 的设计与实现已经做了大量的优化与改进，但距离能运行在 RAM 以 KB 为单位的设备上还差得很远。这不禁使人产生疑问，同样是对统一标准的实现，JerryScript 凭什么做到运行在 RAM 低于 64KB，ROM 低于 200KB 的设备上这种骚操作。本文是对 JerryScript 的官方文档 的翻译。 如上图，Parser(解析器) 和 VM(虚拟机) 是 JerryScript 的两个核心组件。一般来说 JerryScript 运行的基本流程，首先，Parser 将加载到的 JS 标准代码解析成具有特殊格式的字节码，然后由 VM 对字节码进行执行。 Parser在 JerryScript 里，Parser 被设计为 recursive descent parser（递归下降解析器），这样的解析器可以直接将标准 JS 代码转换成字节码而并不像 V8 那样会构建一个 AST。这里的实现依赖以下四个组件：Lexer（词法分析器）、 Scanner、Expression Parser（表达式解析器）以及 Statement Parser（语句解析器）。 Lexer将输入的代码字符串切分成标识符序列，其不仅可以按顺序向前扫描输入字符串，而且可以移动到任意位置。 Scanner对输入的字符串进行预扫描并搜索特定字符，比如这一步可以确定出现 for 的地方代表了常规的循环还是 for-in 循环。 Expression Parser负责解析 JavaScript 表达式。 Statement Parser负责解析 JavaScript 语句。 上图展示了 Parser 中几个主要组件的相互作用，函数 parser_parse_source 对输入的 ES 源代码进行解析和编译，当遇到函数时，调用 parser_parse_function对代码进行递归操作，包括参数解析和上下文处理。解析之后，parser_post_processing 函数转储创建的操作码并返回一个 ecma_compiled_code_t * 指针，它指向已编译的字节码序列。 Byte-code与其他 JS 引擎的实现相比，JerryScript 实现了更加紧凑的字节码形式（CBC），和其他只关注性能的实现相比，一方面减少了字节码的内存消耗，同时又具有可观的性能。CBC 类似于 CISC 指令集，可为频繁的操作分配较短的指令。 许多指令表示多个原子操作，减少了字节码体积，这类似于一种数据压缩方法。 编译的字节码的内存布局 header 表示一个具有多个域的 cbc_compiled_code 结构，这些域包含了字节码的关键属性。 literial 部分是一个 ecma 值的数组，这些值包含了 ECMAScript 定义的数据类型，比如 string、number、function等等。该数组长度由 header 中的 literal_end 字段指定。 CBC instruction list 是一系列的字节码指令，他们代表编译后的代码。 字节码内存布局 每一个字节码都由 opcode 开头。常见指令的 opcode 为1字节，反之稀有指令的为2字节。稀有指令的第一个字节始终为零（CBC_EXT_OPCODE），第二个字节表示扩展操作码。 常见指令和稀有指令的名称分别以 CBC_ 和CBC_EXT_ 前缀开头。 由于可以定义 255个公共指令（不包括零值）和256个稀有指令，因此 opcode 的最大个数是 511，目前大约有215条常见指令和70条稀有指令可用。 在 CBC 中有3种字节码参数： byte argument（字节参数）：介于0~255之间的值，通常代表操作码操作调用的参数计数（函数、new、eval等） literal argument（字面量参数）：在header中介于0~literal_end（包含0）之间的整数索引的域 relative branch（相对分支参数）：长度为1~3个字节的偏移量。分支参数也可能代表指令范围的结尾。 例如，CBC_EXT_WITH_CREATE_CONTEXT 的 branch 参数显示 with 语句的结尾。 更确切地说，with子句中最后一条指令之后的位置 参数之间的组合限于以下7种情况： 无参数 只有一个字面量参数 只有一个字节参数 只有一个分支参数 一个字节参数和一个字面量参数 两个字面量参数 三个字面量参数 Literal（字面量）字面量被按照不同的类型组成字面量组，这与为每个字面量分配标志位相比更加节省空间。（以下提到的范围代表大于或等于范围左侧和小于右侧的那些标记。例如，字节码标头的ident_end和literal_end字段之间的范围包含这些标记， 大于或等于ident_end且小于literal_end。如果ident_end等于literal_end，则范围为空。） identifiers（标识符） 和 values（值） 是两个主要的字面量组： identifier：表示变量的名字。在 header 中字面量值介于0~ident_end之间。这种字面量必须为 string 或 undefined。undefined只能用来表示该字面量无法通过字面量名字访问到的情况。比如 function () {arg, arg}有两个参数，但这里的 arg 只能用来引用第二个参数。在这种情况下，第一个参数的名字就是 undefined。此外，诸如 CSE 之类的优化也可能引入不带名称的字面量。 value：表示立即值的引用。字面量值介于 ident_end 和 const_literal_end 之间的数字或字符串等。这种字面量可以直接被 VM 所使用。字面量值介于 const_literal_end 和 literal_end 的是模板字面量，比如函数和正则表达式。每次访问这类值都需要构造一个新对象。 identifiers 还有另外两个子组。寄存器是存储在函数调用堆栈中的那些标识符。 参数是由调用程序函数传递的那些寄存器。 在 CBC 中有两种类型的字面量编码，都是可变长度，1或2个字节。 small：最多可以编码511个字面量 单字节编码 0 - 254 之间的字面量 1byte[0] &#x3D; literal_index 双字节编码 255 - 510 之间的字面量 12byte[0] &#x3D; 0xffbyte[1] &#x3D; literal_index - 0xff full：最多可以编码 32767 个字面量 单字节编码 0 - 127 之间的字面量 1byte[0] &#x3D; literal_index 双字节编码 128 - 32767 之间的字面量 12byte[0] &#x3D; (literal_index &gt;&gt; 8) | 0x80byte[1] &#x3D; (literal_index &amp; 0xff) 因为大多数函数需要的字面量小于 255，所以 small 编码为所有字面量提供了一个单字节的字面量索引。与 full 编码相比，small 编码占用更少的空间但是范围有限。 Literal StoreJerryScript 没有用于字面量的全局字符串表，但是将它们存储在文字存储中。 在解析阶段，如果出现一个新的字面量，若其标识符与现有的标识符相同，则不会再次存储该字符串，但会使用字面量存储区中的标识符。 如果一个新的字面量不在Literal Store中，它将被插入。 Byte-code Categories（字节码类别）字节码可以被分为四个主要的类别： Push 字节码Call 字节码Arithmetic, Logical, Bitwise and Assignment 字节码（算数、逻辑、位、赋值）Branch 字节码Snapshot（快照）编译后的字节码可以保存到快照中，也可以加载回执行。 直接执行快照可以节省解析源的内存消耗和性能成本。 也可以直接从 ROM 执行快照，在这种情况下，还可以节省将快照加载到内存中的开销。 Virtual Machine（虚拟机）虚拟机是一个解释器，可逐一执行字节码指令。 解释的函数是位于 ./jerry-core/vm/vm.c 的 vm_run。 vm_loop是虚拟机的主循环，它具有非递归特性。 这意味着在函数调用的情况下，它不会递归地调用自身而是返回，这具有的好处是与递归实现相比不会加重堆栈。 ECMA引擎中 ECMA 组件负责以下四个功能： 数据表示 运行时 GC 数据表示数据表示的主要结构是 ECMA_value，这个结构中低三位编码了数据标签，用来确定数据类型： simple number string object symbol error 如果是数字，字符串和对象类型，则该值包含一个编码的指针，对于基础值是一个预定义的常量，可以是： undefined null true false empty (未初始化的值) 压缩指针为了节省堆空间，引入了压缩指针： 这些指针是 8 字节对齐的16位指针，可以寻址 512 Kb的内存，这也是 JerryScript堆的最大容量。 为了支持更多的内存，可以在构建时加上“ –cpointer_32_bit on”，将压缩指针的大小扩展到 32位，以覆盖 32位系统的整个地址空间。 “未压缩的指针”会将内存消耗增加大约20％。 数字根据 IEEE 754标准有两种可能的数字表示形式：默认值是8字节（双精度），但是引擎也支持将 JERRY_NUMBER_TYPE_FLOAT64设置为0来支持4字节（单精度）表示方式。 不支持多次引用单个分配的数字。每个引用都拥有自己的副本。 字符串JerryScript中的字符串不仅是字符序列，而且还可以包含数字和所谓的 magic ID。 对于常见的字符序列（在 ./jerry-core/lit/lit-magic-strings.ini 中定义），只读存储器中有一个表，其中包含 magic ID和字符序列对。 如果一个字符串已经在此表中了，则将存储其字符串的 magic ID 而非字符序列本身。 使用数字可加快属性访问以达到节省内存的目的。 Object / Lexical Environment（词汇环境）对象可以是常规数据对象或词法环境对象。 与其他数据类型不同，对象可以具有对其他数据类型的引用（称为属性）。 由于有循环引用，引用计数并不总是足以确定死对象。 因此，链列表是由所有现有对象组成的，可用于在垃圾回收期间查找未引用的对象。 每个对象的 gc-next 指针显示链表中的下一个分配对象。 Lexical environments 在 JerryScript 中实现为对象，因为其包含像对象一样的键值对（称为绑定）。 这简化了实现并减小了代码大小。 这些对象表现为如下结构： 引用计数器–硬（非属性）引用的数量 GC 的下一个对象指针 类型（函数对象或词汇环境等） 对象属性 对象有一个包含其属性的链表。此链表实际上包含属性对，为了节省内存：属性占7位，其类型字段占2位，共9位，这样一个字节就不够用需要占用两个字节，因此，将两个属性（14位）与2位的类型字段放在一起这样就能沾满2字节。 property hashmap（属性hash表）如果属性对的数量达到限制（当前此限制定义为16），则在属性对列表的第一个位置插入一个 Property Hashmap，以便使用它来查找属性，而不是通过在属性对上线性迭代来查询。 属性哈希表包含2^n个元素，其中 2^n 大于对象的属性数。 每个元素可以具有值的树类型： null，指代空元素 delete，指代被删除的元素，或者 对现有对象的引用 hashmap 是必须返回的类型的缓存，这意味着可以通过它找到对象所有的属性。 内部属性内部属性是一些特殊的属性，这些属性包含无法由 JavaScript 代码访问的元信息，但对引擎本身很重要。 内部属性的一些示例如下所示： [[Class]] – 对象的类（类型）（ECMA 定义） [[Code]] – 指向函数字节码的指针 native code（原生代码）– 指向原生函数代码的指针 Boolean [[PrimitiveValue]]（基础值）– 存储 Boolean 对象的 bool 值 Boolean [[PrimitiveValue]]（基础值）– 存储 Number 对象的数值 LCacheLCache是用于查找由对象和属性名称指定的属性的哈希表。 LCache 的对象-名称-属性布局在一行中连续显示多次，如下图： 访问属性时，将从所需的属性名称中提取hash值，然后使用该哈希值对 LCache 进行索引。 然后在索引行中搜索指定的对象和属性名称。 值得注意的是，如果在 LCache 中找不到指定的属性，这并不意味着它不存在（即LCache是可能返回的缓存）。 如果找不到该属性，则将在对象的属性列表中对其进行搜索，如果找到该属性则会将该属性放入LCache中。 CollectionsCollections 是类数组数据结构，优化用于节省内存。事实上，Collections是一个链表，其元素并非单个元素，而是一个包含多个元素的数组。 Exception Handling（异常处理）为了实现异常处理，JerryScript 的返回值能指示其错误或异常操作。其返回值是一个 ECMA 值，若发生错误操作则返回 ECMA_VALUE_ERROR 值。 Value Management and Ownership（值管理和所有权）引擎存储的每个 ECMA 值都与一个虚拟的 “所有权” 相关联，该所有权定义了如何管理该值：当不再需要它时何时释放它，以及如何将该值传递给其他功能。 最初，值是由其所有者（即用有所有权）分配的。 所有者有责任释放该值。 当将值作为参数传递给函数时，其所有权不会被传递，被调用函数必须制作一个自己的值副本。 但是，只要函数返回值，所有权就会传递，因此调用者将负责释放它。","permalink":"https://txiaozhe.github.io/2019/11/18/learning-jerryscript-design/","photos":[]},{"tags":[{"name":"Libuv","slug":"Libuv","permalink":"https://txiaozhe.github.io/tags/Libuv/"}],"title":"libuv 架构设计概述","date":"2019/10/18","text":"libuv 是一个原本为 Node.js 而编写，围绕着事件驱动的异步 I/O 模型而设计的跨平台库。 这个库为多个不同的I/O 循环机制提供了简单的抽象，如：‘handles’ 和 ‘streams’ 为 sockets 和其他实体提供高度抽象；除此之外也提供了跨平台文件 I/O 和线程功能。 libuv 架构如图： Handles(句柄) 和 requests(请求)libuv 结合事件循环为用户提供了两个协作对象的抽象：handles 和 requests。 Handles 表示活动时能执行某些操作的长期存活对象： prepare handle 在活动时每次循环迭代都会调用一次其回调。 TCP 服务器 handler 会在每次有新连接时调用其连接回调。 Requests 通常表示短期存在的操作。这些操作可以在一个handle上执行，例如：写请求在被用于在handle上写数据；或者独立的： getaddrinfo 请求不需要handle而直接在循环迭代中运行。 I/O 循环I/O (或事件) 循环是libuv 的核心部分。其构建了所有的 I/O 操作，并将其绑定到单个线程上。因此只要每个事件循环运行在不同的线程中，就可以同时运行多个事件循环。除非另有说明，libuv 事件循环（或任何涉及到事件循环或handle的 API）都不是线程安全的。 事件循环遵循常见的单线程异步 I/O 方式：在给定平台上，所有（网络）I/O 都使用最佳的机制在非阻塞的套接字中轮询执行：如 linux 的epoll；OSX或BSDs 的kqueue；SunOS 的event ports以及Windows的IOCP。作为循环迭代的一部分，循环将阻塞等待已添加到循环器中的套接字上的I/O 活动，并触发回调指示套接字条件（可读或可写的挂起）以便 handle 可以读取、写入或执行所需的 I/O 操作。 为了更好地理解事件循环的运作方式，下图说明了循环迭代的所有阶段： 更新 ‘now’。事件循环在开始处缓存当前时间以减少与时间相关的系统调用。 若循环是存活的则开始迭代，否则立即退出。那么什么情况下认为循环是存活的？当循环中存在活动的handle或被引用的 handle、活动中的请求或closing handles 时则认为循环是存活的。 执行到期的计时器。调用所有到期的计时器的回调。 调用上一轮循环推迟的回调。大多数情况下会在轮训 I/O 之后调用所有 I/O 回调。某些情况下这类回调会被推迟到下一个循环迭代。被推迟的 I/O 回调将在此时运行。 调用 idle handle。如果空闲handle是存活的，则会在每个循环中调用它们。 调用 prepare（就绪）handle。循环阻塞 I/O 前prepare handle回调将得到调用。 计算循环超时。在阻塞 I/O 前，循环会计算阻塞的时间，以下是计算超时的规则： 如果循环使用 UV_RUN_NOWAIT 标志运行，则超时为0； 如果循环即将停止（uv_stop() 被调用），则超时为0； 如果不存在任何存活的 handles 和 request，则超时为0； 如果有任何空闲的handle处于活动状态，则超时为0； 如果有任何要关闭的handle，则超时为0； 如果以上情况都不匹配，则采用最接近的定时器超时，或者当没有活动的定时器时，则为无穷大。 I/O 循环模块。此时，循环将在上一步计算的持续时间内阻塞 I/O，正在监视给定文件描述符的读写操作的所有与I / O相关的 handle 都将调用其回调。 调用 check handle。在 I/O 阻塞循环之后，check handle立即调用其回调，check handle 基本上对应着 prepare handles。 调用 close 回调。当通过调用 uv_close() 关闭 handle时将调用close 回调。 使用 UV_RUN_ONCE 标志运行的情况下的特殊阶段。阻塞 I/O 后可能没有触发任何 I/O 回调，但是此时已经过去了一段时间，因此可能会有到期的计时器，此时这些计时器回调将得到调用。 迭代末尾。如果循环是使用 UV_RUN_NOWAIT 或 UV_RUN_ONCE 模式运行的，则迭代将结束，并且uv_run() 将返回。如果循环是使用 UV_RUN_DEFAULT 运行的，那么如果循环仍然存活，则将从头开始继续，否则也将结束。 划重点：libuv 使用线程池使异步文件 I/O 操作成为可能，但是网络 I/O 始终在单个线程（每个循环的线程）中执行。 注意：尽管轮训机制不同，但libuv使执行模型在 Unix 系统和 Windows 之间保持一致。 文件 I/O与网络 I/O 不同，libuv 特定平台下没有可依赖的 I/O 操作原语，因此当前的实现方式是在线程池中运行阻塞的文件 I/O 操作。 有关跨平台文件 I/O 的详尽说明，查看此文章。 当前 libuv 使用全局线程池，所有循环都可以在该线程池上排队工作。当前在此线程池上运行3种类型的操作： 文件系统操作 DNS 函数（getaddrinfo 和 getnameinfo） 用户通过 uv_queue_work() 运行的特定代码 警告：有关更多详细信息，查看 “线程池工作调度” 部分，但是请记住，线程池的大小是非常有限的。","permalink":"https://txiaozhe.github.io/2019/10/18/libuv-design/","photos":[]},{"tags":[{"name":"Life","slug":"Life","permalink":"https://txiaozhe.github.io/tags/Life/"},{"name":"Job","slug":"Job","permalink":"https://txiaozhe.github.io/tags/Job/"}],"title":"多思无益","date":"2019/06/23","text":"今天约了一个朋友来家里吃饭，我烧了两斤的小龙虾，烹饪技术已经越来越娴熟。中间聊起行业和工作来，自诩有两年的从业经验，也能吹一点牛逼。他问我，python用处大吗？值得学习吗？我问他：你又不是做技术的，你学这个做什么用呢？他回答，据说用在数据处理上很方便很有用？！我心里当然是想打击一下他的，因为我觉得真的没用嘛！我是这样解释的，确实，现在行业内将python这门语言大量用在大数据处理，人工智能方面，确实很方便很实用，但这也仅仅是一门语言一个工具而已，除此之外恐怕也没有更多，也许我们可以更多地关注底下的东西。 我们常常说大数据，那什么样的数据算是大数据呢？是很多条数据吗？那多少条算多，一万条算多吗？一百万条算多吗？也许算吧！但我并不觉得这就是大数据。我总是希望将我的想法用简洁易懂的语言描述给不懂的人，于是我给他打了个比方。我说，在你眼里，大数据应该是一条河，一条滚滚向前奔流的河，而这条河的任意一段都无法展现这条河的真实面貌，你只能通过一些观察手段得到它某时某刻以某种方式展现在你面前的一个宏观体现。我想，这也是为什么大数据的结果往往接近现实的本质。 他可能没有听得很明白吧，不过我内心还是满足的，又在不懂行的人面前强行卖弄了一波。过去的半年多曾经在一家区块链公司任职，内心一度异常挣扎，挣扎的不是企业本身，而是自己有太多的看不懂。我常常思考价值的本质，或者说什么才是真正有价值的东西？是黄金？是纸币？亦或是那一串没有任何文本意义的比特币秘钥字符串？金融市场的价值来源在哪里？背后的价值支撑又在哪里？……历史起起伏伏又总是惊人相似，思考的结果，却只有两个字：信用？！ 在互联网行业内，我是一名程序员，不过我更喜欢被叫做工程师。我也总是自称开源（开放源代码）爱好者，不过代码贡献不算很多，也许只能算是一个伪开源爱好者吧。但我也常常思考开源的价值在哪里，也许我心里也是有一些答案的，也许是某种模式，也许是某种生态。我也是有一些开源理念和愿景的，跳出技术的思考模式，我常常觉得技术的价值并不在技术本身，而在于技术构建的产品和商业模式上，这种话语可能对于技术圈的人来说不是很中听吧！但事实出于思考与辩论。在我的理念里，技术是应该有它普世的价值的，这种价值看起来就在于是否降低了社会运作成本，是否打破某些壁垒，是否使众生平等…… 当然，过多的思考是无效的，当下先把技术搞懂~","permalink":"https://txiaozhe.github.io/2019/06/23/no-more-consider/","photos":[]},{"tags":[{"name":"Life","slug":"Life","permalink":"https://txiaozhe.github.io/tags/Life/"},{"name":"Job","slug":"Job","permalink":"https://txiaozhe.github.io/tags/Job/"}],"title":"记 Rokid 两周以及一次 ShadowNode MQTT 的 bug","date":"2019/06/20","text":"2019年6月某天，入职Rokid第2周，逐渐适应了新的办公环境和新的做事方式，开始接触IOT和端开发的概念，技术上慢慢地从服务端过渡到端开发，刚开始还是有些不适应，先讲一下个人感受吧！ 以前做过大规模的分布式系统，也做过小型的Web API，总结下来，做服务端开发要考虑更多的是Web接口、请求负载、网络性能以及如何更好地和客户端交互，大多数情况下不需要考虑太多机器的性能问题，因为一般情况下机器性能都是过剩和冗余的，对于企业来说，能花钱加机器解决的问题也一定不是问题，而且现在云服务盛行，大量的工具、平台都被打包成云服务出售，只要花上一点小钱钱就能获得很好的基础设施支撑，开发起来不要太爽，像把服务器性能榨干这种事情基本是被抛在脑后的。但端开发就是另外一种情景了，和服务端性能压力来自外部请求不同，端上的性能问题来自设备自身，当下呈现在端开发工程师面前的主要是嵌入式开发板、智能家居设备和可穿戴式设备等，CPU和内存资源少得可怜，同时也不可能像服务端那样通过增加设备来横向扩展，这就需要开发者去耐心地打磨底层的代码，想为所欲为地写代码秀操作？不存在的，碰到性能瓶颈？C语言伺候。 开始的这两周，主要以熟悉业务为主，开始还是有点吃力的，难点在于思维方式的转化，幸运的是大佬们都很耐心和细心，指导起来也不遗余力。熟悉业务以线上的各种bug为切入点，这两天就碰到一个关于MQTT协议的问题，经过两天的修复和审核，总算是将补丁打入主分支。 MQTT(消息队列遥测传输协议)，是一种基于发布/订阅模式的轻量级应用层通信协议，基于TCP协议构建，因为其低开销、低带宽占用的特点，使其在物联网(IOT)方面有着较广泛的应用。Rokid产品线基于YodaOS + ShadowNode 构建 IOT 应用，并使用 ShadowNode 内置的 MQTT 作为设备与移动端之间的通信协议。在某一时间点，用户爆出大量设备不在线的问题，初步分析是 MQTT 的问题，拿了一段 MQTT 订阅和发布的测试代码在本地运行，发现用 node 命令运行是没问题的，用 ShadowNode 运行就会出现断开连接的问题，确实是ShadowNode 本身的问题，再细致分析，发现客户端在 SUBSCRIBE 的时候会导致断开连接，于是深入MQTT源码，打印出 SUBSCRIBE 时发送的报文，再将其在 node 环境中运行打印正常的报文进行对比： 1282 2d 00 00 00 28 2f 64 65 76 69 63 65 2f 43 4d 43 43 2d 33 30 36 37 31 2d... # 错误报文82 2d 8d 05 00 28 2f 64 65 76 69 63 65 2f 43 4d 43 43 2d 33 30 36 37 31 2d... # 正确报文 对比正确的和错误的报文，发现第三和第四个字节是不一样的，看来是报文组装出问题了，为了验证这个猜想，我将正确的报文内容转成二进制通过ShadowNode发送，果然正确订阅，看来确实是协议的问题。鉴于本人也是第一次接触MQTT协议，没办法，只能去看MQTT协议文档了，本次修复查阅的是 3.1.1 版本的文档。 简单阐述一下MQTT协议，为了节省性能开支，其报文设计得相当紧凑环保。MQTT的报文分为固定报头、可变报头和有效载荷三部分，固定报头是必须存在的，用于描述报文类型、等级等信息，可变报头不一定存在，这取决于报文的类型，有效载荷存放的是通信内容。如上所示，前两个字节是固定报头，第一个字节（82）前四位表示类型，这里8表示SUBSCRIBE消息，后四位表示指定控制报文类型的标志位，目前只用到0010，也就是2。第二个字节表示消息的剩余长度，也就是可变报头+负载的长度总和。第三第四个字节为可变报头部分，包含一个用于确认消息传递状态的报文标识符（PacketId），该标识符由报文类型决定存在与否，当发布PUBLISH消息且QoS &gt; 0时是必须存在的，且发送 SUBCRIBE 消息时也是必须存在的，问题就出在这里，在 ShadowNode 的 MQTT 协议实现中会传入一个从0开始递增的PacketId，首次 SUBCRIBE 时该 PacketId 为0，这就导致底层处理时认为该位为空而不写入该段报文，也就是为什么上面看到的错误报文的第三和第四字节为00 00，正常情况下应该写入一个两字节的非零数字作为PacketId。至于开始时为什么不出错，也许是应用该MQTT实现的一端开始时并没有真正将这个PacketId 用来校验消息状态，而后期迭代的时候开发人员良心发现突然又校验了，从而导致报文错误。Bug 原因已找出，是时候修复一下了，由于 ShadowNode 中 MQTT 的实现还没有很完善，后期还需要做更多的适配，而业务线又出现 Bug 需要紧急修复，因此目前只做了应急措施，将上述 PacketId 的递增初始值设置为1，进而解决了该问题，真是一个数字导致的血案~ 为了适应协议文档中对QoS的处理，本次补丁还对 QoS 进行了初步的校验，补丁地址，这是情急之下做的紧急修复，如有问题欢迎在 ISSUE 中提出 :) 两周下来，切实感受到 Rokid 确实是一片丛林，挣扎并有趣~ 可期！","permalink":"https://txiaozhe.github.io/2019/06/20/mqtt-hotfix/","photos":[]},{"tags":[{"name":"CockroachDB","slug":"CockroachDB","permalink":"https://txiaozhe.github.io/tags/CockroachDB/"},{"name":"SQL","slug":"SQL","permalink":"https://txiaozhe.github.io/tags/SQL/"}],"title":"添加一个新的SQL语句","date":"2019/04/24","text":"前言CockroachDB是著名的开源NewSQL数据库，对外提供了标准的SQL接口。上一篇文章《CockroachDB的Parser模块实现》介绍了CockroachDB中Parser模块，主要通过词法解析器将SQL语句解析成Token，然后通过语法解析器生成抽象语法树。本文将介绍如何在CockroachDB中添加一个新的SQL语法类型，来实现用户自定义的功能，并添加相应的测试，从而加深对相应模块的代码及原理的理解。 添加一个新的SQL语句添加一个新的SQL语句，首先需要在SQL parser中添加必要的语法规则。CockroachDB的parser是通过 goyacc （go语言构建的一个yacc编译器）解析语法规则文件（pkg/sql/parser/sql.y）生成的。parser生成一颗抽象语法树（AST*），其树节点的定义在代码目录 *pkg/sql/sem/tree 下。 在parser中添加一个新的SQL语句有三个关键部分： 添加新的关键字； 添加语法解析规则； 添加新的语法节点类型 我们将尝试在CockroachDB v2.1中添加一个新的SQL语句：FROBNICATE ，这个SQL语句支持三种语法，功能如下： FROBNICATE CLUSTER ：在服务端打印 “It’s FrobnicateModeCluster” FROBNICATE SESSION：在服务端打印 “It’s FrobnicateModeSession” FROBNICATE ALL：在服务端打印 “It’s FrobnicateModeALL” 添加新的关键字第一步需要先定义关键字。在pkg/sql/parser/sql.y 文件中搜索”%token”，可以看到声明了许多token，例如我们语法中需要用到的SESSION、CLUSTER、ALL*都已经存在了，因此我们只需要添加关键字 *FROBNICATE 即可，如下所示： 1%token &lt;str&gt; FROBNICATE 如果关键字可以出现在标识符选项中，则必须保留该关键字（在需要使用它的地方，例如在列名中，必须使用双引号引起来），因此我们还需要将该关键字添加到”unreserved keywords”列表中，避免与标识符混淆。 1234unreserved_keyword:....| FROBNICATE... 至此词法分析器已经能识别我们所有的关键字了，接下来需要告诉语法解析器如何处理新的语句。 添加语法解析规则添加语法解析规则涉及到下列三个部分： 类型列表 语法case列表 子句解析规则 在 sql.y 文件中搜索”tree.Statement”，可以看到定义好的类型列表，在这里添加一个新的语法类型，如下所示： 1%type &lt;tree.Statement&gt; frobnicate_stmt 然后搜索 “stmt: “，为新的语句类型添加一个case： 1234stmt:...| frobnicate_stmt &#x2F;&#x2F; EXTEND WITH HELP: FROBNICATE... 最后，我们需要在stmt中为新的语句添加语法规则及相应的帮助信息，如下所示： 1234567&#x2F;&#x2F; %Help: FROBNICATE - show the simple message&#x2F;&#x2F; %Category: Misc&#x2F;&#x2F; %Text: FROBNICATE &#123; CLUSTER | SESSION | ALL &#125;frobnicate_stmt:FROBNICATE CLUSTER &#123; return unimplemented(sqllex, &quot;frobnicate cluster&quot;) &#125;| FROBNICATE SESSION &#123; return unimplemented(sqllex, &quot;frobnicate session&quot;) &#125;| FROBNICATE ALL &#123; return unimplemented(sqllex, &quot;frobnicate all&quot;) &#125; 至此，parser已经能够识别新的语法类型并提示相应信息了。此处我们暂时使用unimplemented来代替该语法具体的操作，后续我们会继续完善该部分内容。 我们来尝试使用新的语法，首先需要产生 sql.go 文件： 12345~/go/src/github.com/cockroachdb/cockroach$ make generate...Type checking sql.yCompiling sql.go... 然后重新编译： 123~/go/src/github.com/cockroachdb/cockroach$ make build...github.com/cockroachdb/cockroach 使用新编译的二进制文件，起一个CockroachDB单节点实例： 1234$ rm -fr cockroach-data/ &amp;&amp; ./cockroach start --insecure...status: initialized new cluster... 另起一个终端，运行刚才添加的新语句： 这里虽然出现了umimplemented 报错，提示该语句还未完成，不过这时已经可以解析该语法了。如果执行一个不存在的语句，提示的错误则是 syntax error： 添加新的语法节点类型现在我们已经可以解析相关语法，接下来还需要为该语句添加适当的语义。我们需要一个AST（抽象语法树）节点来将语句的结构信息从parser传递到runtime。 上文中我们在sql.y中添加过%type &lt;tree.Statement&gt;，因此我们还需要实现tree.Statement接口，该接口的定义在pkg/sql/sem/tree/stmt.go中，它有4个方法需要实现： fmt.Stringer NodeFormatter StatementType() StatementTag() 首先创建一个新文件pkg/sql/sem/tree/frobnicate.go，在该文件中实现相关AST节点： 1234567891011121314151617181920212223242526272829303132333435package parserimport \"bytes\"type Frobnicate struct &#123; Mode FrobnicateMode&#125;var _ Statement = &amp;Frobnicate&#123;&#125;type FrobnicateMode intconst ( FrobnicateModeAll FrobnicateMode = iota FrobnicateModeCluster FrobnicateModeSession)func (node *Frobnicate) StatementType() StatementType &#123; return Ack &#125;func (node *Frobnicate) StatementTag() string &#123; return \"FROBNICATE\" &#125;func (node *Frobnicate) Format(buf *bytes.Buffer, f FmtFlags) &#123; buf.WriteString(\"FROBNICATE \") switch node.Mode &#123; case FrobnicateModeAll: buf.WriteString(\"ALL\") case FrobnicateModeCluster: buf.WriteString(\"CLUSTER\") case FrobnicateModeSession: buf.WriteString(\"SESSION\") default: panic(fmt.Errorf(\"Unknown FROBNICATE mode %v!\", node.Mode)) &#125;&#125;func (node *Frobnicate) String() string &#123; return AsString(node)&#125; 接下来我们需要更新parser，让它在遇到该语句时返回相应的Frobnicate节点。 上文在 sql.y 文件中添加frobnicate_stmt规则时，使用了unimplemented来暂时代替具体实现，现在我们来实现这部分内容： 1234567&#x2F;&#x2F; %Help: FROBNICATE - twiddle the various settings&#x2F;&#x2F; %Category: Misc&#x2F;&#x2F; %Text: FROBNICATE &#123; CLUSTER | SESSION | ALL &#125;frobnicate_stmt:FROBNICATE CLUSTER &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeCluster&#125; &#125;| FROBNICATE SESSION &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeSession&#125; &#125;| FROBNICATE ALL &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeAll&#125; &#125; 重新编译，然后通过客户端运行该语句： 这里返回了一个错误，不过这是一个来自SQL planner的错误，当SQL planner识别到新的语法节点但是不知道该如何处理时就会报这个错误。 我们需要告诉planner如何处理这个语法，相应的代码在 pkg/sql/plan.go 中，我们在newPlan函数中为其添加一个case： 123switch n := stmt.(type) &#123;case *tree.Frobnicate: return p.Frobnicate(ctx, n) 然后我们在 pkg/sql/frobnicate.go 中实现对应的方法： 12345678910package sqlimport ( \"context\" \"fmt\" \"github.com/cockroachdb/cockroach/pkg/sql/sem/tree\")func (p *planner) Frobnicate(ctx context.Context, stmt *tree.Frobnicate) (planNode, error) &#123; return nil, fmt.Errorf(\"We're not quite frobnicating yet...\")&#125; 再次编译并运行： 这里已经根据相应函数内的代码返回了一个错误，接下来我们修改该函数，实现打印出对应信息的功能： 12345678910111213func (p *planner) Frobnicate(ctx context.Context, stmt *tree.Frobnicate) (planNode, error) &#123; switch stmt.Mode &#123; case tree.FrobnicateModeCluster: fmt.Println(\"It's FrobnicateModeCluster\") case tree.FrobnicateModeSession: fmt.Println(\"It's FrobnicateModeSession\") case tree.FrobnicateModeAll: fmt.Println(\"It's FrobnicateModeAll\") default: return nil, fmt.Errorf(\"Unhandled FROBNICATE mode %v!\", stmt.Mode) &#125; return &amp;zeroNode&#123;&#125;, nil&#125; 注意：这里直接返回zeroNode，它是一个不包含任何行和列的planNode，所以客户端将看不到任何数据返回。如果你需要返回一些内容给客户端，可以查看 pkg/sql 包下是否有合适的planNode，或者使用自定义的planNode。 重新编译并运行： 123./cockroach sql --insecure -e \"frobnicate cluster\"./cockroach sql --insecure -e \"frobnicate session\"./cockroach sql --insecure -e \"frobnicate all\" 这时在服务端屏幕可以观察到已经打印出对应的内容： 至此我们已经实现了一个简单的 frobnicate 语法，别忘了最后还有一个重要步骤，添加相应的测试用例。 添加测试用例此处需要为该语法解析添加测试用例，相关测试代码位于 pkg/sql/parser/parse_test.go ，我们只需要在对应的地方加入需要测试的语法即可： 123&#123;&#96;FROBNICATE CLUSTER&#96;&#125;,&#123;&#96;FROBNICATE SESSION&#96;&#125;,&#123;&#96;FROBNICATE ALL&#96;&#125;, 然后运行测试: 1$ make test 如果在上述过程中可以顺利添加语句并成功编译构建，则此处应当可以成功跑通相应的测试用例。 关于SQL语句的功能测试代码在 pkg/sql/logictest/ 下相应文件中，只需要在对应的地方添加新的SQL语句和期望的返回结果即可。由于此处我们仅实现了服务端打印的测试功能，便不具体在此处进行测试，感兴趣的同学可以自行查看对应的测试文件。 给SQL语句添加别名如果我们需要经常运行Frobnicate语句，希望它可以更简洁的话，我们也可以给它添加一个别名FROB，实现过程很简单，只需要在sql.y中添加几行规则即可： 123456789101112unreserved_keyword:...+ | FROB| FROBNICATE...frobnicate_stmt:FROBNICATE CLUSTER &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeCluster&#125; &#125;| FROBNICATE SESSION &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeSession&#125; &#125;| FROBNICATE ALL &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeAll&#125; &#125;+ | FROB CLUSTER &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeCluster&#125; &#125;+ | FROB SESSION &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeSession&#125; &#125;+ | FROB ALL &#123; $$.val &#x3D; &amp;tree.Frobnicate&#123;Mode: tree.FrobnicateModeAll&#125; &#125; 总结本文通过一个添加SQL语句的案例，介绍了SQL语句在CockroachDB代码中的实际解析和处理流程。本文所使用的案例参考了https://github.com/cockroachdb/cockroach/blob/master/docs/codelabs/01-sql-statement.md 中的案例，为了便于读者理解，在实现具体功能时直接在服务端打印内容并返回zeroNode。关于planner和生成执行计划相关的原理及实现，会在后续的SQL引擎系列文章中进行详细介绍。","permalink":"https://txiaozhe.github.io/2019/04/24/add-a-new-sql/","photos":[]},{"tags":[{"name":"Life","slug":"Life","permalink":"https://txiaozhe.github.io/tags/Life/"},{"name":"Job","slug":"Job","permalink":"https://txiaozhe.github.io/tags/Job/"}],"title":"给2019起个好头","date":"2019/01/28","text":"或许是受到某大佬的感染，也有可能是因为最近工作方面的变故比较多，想写点东西，想想几年前我也曾是个喜欢写写文章，小诗，偶尔还学着刻印章的文艺二逼青年~ 我是不玩知乎的，但偶尔有好的文章也会打开来看。这是我在知乎的第一篇文章，希望也能开一个好头。简单介绍我自己吧！本人94年11月生人，妥妥的90后，算是有幸摸到了一点点95后的脑袋。13年上大学，17年毕业，程序猿，毕业前后在一家小创业公司就职，但无奈面临的问题太多太复杂，已经无法妥善解决，公司状况也超出了我的最坏预期，个人财务状况几近破产，于是多方思考后于2017年10月来到杭州（也因为我是浙江人），并就职于全民TV，后由于全民破产不得不出走（还被拖欠工资，想想就气人，手动讨伐），目前就职于一家区块链公司，日常打杂。其实我并非计算机专业出身，本科专业是高分子材料与工程，可以说是跟计算机没有半毛钱关系，至于说为什么会走上这条路，这个过程异常曲折，也曾经被质疑，那些已经足以写一篇文章了，我想说，有困难，有缘分，有机遇，也有努力。 一直以来，我是一个对游戏，玩这些事情无感的人，不过我仍然会去旅行，但不会奔着风景去，我会更加看重我去那个地方能见到什么人，能得到什么收获。大学四年以及毕业一年半以来，去的地方不多，北京、上海、深圳、苏州、南昌…，每当去那些大城市，总会带着一些事情或者要见某个人的目的而去，见完之后急匆匆赶上返程的火车，家里人也常常埋怨我，既然去了，何不多玩几天？我也总是敷衍：下次吧，以后有的是机会！在我眼里北京是一个没有印象中那么发达的地方，北京人不友好，还有，雾霾真的非常严重！上海依然繁华，而苏州也是一个美丽而又富有韵味的城市，还是蛮讨人喜欢的，深圳，节奏很快吧，至于南昌，emmmm…，但总体对比下来，我仍然最喜欢我的杭州，我想杭州是有一些东西在吸引着我的，西湖，湿地，四季…… 在杭州也已有一年多了，工作上面没有当初想的那么的一帆风顺，在第一份正式工作上就经历了破产倒闭，大小目标一再搁浅，也没有像当初想的那样找到女朋友，但我至始至终都给自己一个信念，不管在哪里，不论最终结局如何，都要心存感激，我也始终感恩全民TV给我带来的知识与成长，也相信未来会变好。 我想我仍然是一个很有心的人，和很多年前一样，那时候的我，会以献血来纪念成年，会凌晨三点一个人跑上山去看日出，会因为喜欢一个人做很多傻事。而现在的我会在周末邀请朋友们来家里吃饭，小小的出租屋，我也会做一桌好菜，是的，我喜欢做菜，相比吃，我更享受那个过程。饭桌上谈笑风生，很无聊，也很有趣。桌上常备一束花，有时是百合，秋天可以摆桂花，简单点就绿萝，快入春了，栀子花会很香。一个人的生活，简单而又丰富。最近看了一篇文章，北大研究生放弃白领工作从事外卖员，起初感觉又是这种噱头式的狗血故事，但我硬是耐着性子看完了那篇两万多字的文章，后来发现人家确实比我强多了，至少他在这个过程中思考出了一些结论，而我呢？我也曾经多次把自己投放到社会底层的工作中去，初中毕业走上社会，做过服务员，发过传单，甚至在工地上做过苦力，然而对于这些经历，好像我的收获只有在别人面前吹嘘自己的经历如何丰富，走在钱塘江边上的时候指着那幢大楼说自己曾经是它的建设者。而这一切，对于现在的我，却显得没有任何意义。在那些做苦力的日子里，我学着他们抽烟，讲脏话，打架斗殴，骑着车在路上狂飙的时候，感觉自己没有那么渺小，整个世界都是我的。在那些有些黑暗的地方，我曾经看到过一些不一样的社会与现实，甚至有过一种融入进去混沌一生的错觉，但终究还是走了出来，我也一直庆幸，我想，我跟他们是不一样的。 我常常思考很无聊的问题，比如如何去做事！我的工作经历也许相当“丰富”了，但我依然没有想明白，我的解决办法是不要想，先去做。就像在大学的时候，自学计算机，怎样描述那时候的困难与努力呢？我印象最深的是，一个懵懂的学弟问我怎样学计算机，我跟他说，图书馆，二楼，理科阅览室，靠近窗户那一排书架，中间一层摆满了计算机的书，都是我放在那里的，感兴趣可以去翻一下！那时候的点点滴滴，已经化解为一个又一个的坐标，中间也受到很多的质疑，但我总是坚定。到现在，工作之余，我会关注社区，开始无偿为一些开源项目贡献，也因此结识了很多的小伙伴。现在，我开始有了一个信念：把事情做到位了，会有意外的收获。我一直在寻找一些真正有价值的东西，我发现，我的坚持开始变得有价值。 入冬以来，也许很多人的感受是一样的，冷。确实，大环境的变故总是那么猝不及防，而我们作为其中的个体又显得那么无力，我自己的规划也在一次次重组、裁员的消息中无所适从。昨天见了一个朋友，闲聊之中，我跟他说，最近很颓，不知所措。尽管如此，我也还是获取到正能量的，无论如何，相信一切都会变好~ 大学毕业一路以来的思考与感受，可笑勿喷 :)","permalink":"https://txiaozhe.github.io/2019/01/28/2019-begin/","photos":[]},{"tags":[{"name":"ShadowNode","slug":"ShadowNode","permalink":"https://txiaozhe.github.io/tags/ShadowNode/"},{"name":"Nodejs","slug":"Nodejs","permalink":"https://txiaozhe.github.io/tags/Nodejs/"}],"title":"ShadowNode 源码解析之 module","date":"2018/12/20","text":"ShadowNode 是一款可以运行于嵌入式设备的js运行时，基于Samsung的iotjs项目开发，和node相比，其具有更小的内存占用和更快的启动速度，不过作为contributor之一，给我很直观的感受就是ShadowNode具有极快的编译速度，开发起来也更加顺畅。我从2018年10月开始利用业余时间参与ShadowNode的开发和维护，为其提交了数个补丁和特性，因此也逐渐对其有了一定的了解，在此我将对ShadowNode从源码的角度对其进行解析以及我个人对ShadowNode的一些疑惑和思考。因为大部分实现与node一致，而且团队也一直希望将ShadowNode做到与node兼容，因此此解析也适用于理解node源码。在此也希望ShadowNode能越来越普及，并为node社区开拓一片新的领域。 本文主要讲述ShadowNode中module模块的实现。module是node中最重要的模块之一，在ShadowNode中也是如此。和node一样，ShadowNode也支持CommonJS的模块形式，实现方式略有不同，但使用方式与node基本一致。 module模块在node和ShadowNode中的重要性不言而喻，从启动时便要用于加载脚本。废话不多说，接下来先解析一波源码，我们从入口文件ShadowNode/src/js/iotjs.js（为什么还要叫iotjs呢？其实我一直想向团队建议改个名字，比如snode啥的@yorkie:) ）开始，这里面包含了一个IIFE的函数，ShadowNode/src/js/iotjs.js line: 23 12345678910111213141516171819202122function Module(id) &#123; this.id = id; this.exports = &#123;&#125;;&#125;Module.cache = &#123;&#125;;Module.require = function(id) &#123; if (id === 'native') &#123; return Module; &#125; if (Module.cache[id]) &#123; return Module.cache[id].exports; &#125; var module = new Module(id); Module.cache[id] = module; module.compile(); return module.exports;&#125;; 可以看到这里定义了一个Module类，但这还不是我们日常使用的那个module模块，这里进行了if (id === &#39;native&#39;)的判断，后面会用到，然后从缓存中获取模块，我们可以看到不管是node还是ShadowNode，缓存的概念都是一以贯之的，这极大地提升了模块加载的性能，最后将模块返回。而后移到ShadowNode/src/js/iotjs.js line: 51 1var module = Module.require('module'); 这里调用了上述Module类的require静态方法来加载真正的module模块所在地：ShadowNode/src/js/module.js，并运行compile成员方法，里面会调用process.compileModule()方法，这是用c代码实现的内置process模块，在此我不详细讲述process的内容，之后会用专门的篇幅进行解析。compileModule() 用于将模块载入内存，成为运行时的一部分，也就可以用于运行与调用了。简单来说，这入口文件主要执行了诸如：ShadowNode/src/js/iotjs.js line: 384 123global.console = Module.require('console');global.Buffer = Module.require('buffer');global.Promise = Module.require('promise'); 以及：ShadowNode/src/js/iotjs.js line: 496 12process.exit = function(code) &#123; ... 等我们熟悉的全局模块、方法以及常量的定义与加载操作，为系统启动做足准备工作，但这不是我们现在所关心的，因此移步至 ShadowNode/src/js/iotjs.js line: 603 12var m = Module.require('module');m.runMain(); 这里再次加载了一个上述真正的module模块实现文件并执行了其静态的runMain方法，因此我们移步至ShadowNode/src/js/module.js：line: 335 12345678910iotjs_module_t.runMain = function() &#123; if (process.debuggerWaitSource) &#123; var fn = process.debuggerSourceCompile(); fn.call(); &#125; else &#123; var filename = mainModule.filename = process.argv[1]; mainModule.exports = iotjs_module_t.load(filename, null); &#125; while (process._onNextTick());&#125;; 我们现在着重关注以下代码： 12var filename = mainModule.filename = process.argv[1];mainModule.exports = iotjs_module_t.load(filename, null); 这里将process.argv[1]所指代的变量作为文件名，也就是当执行$ iotjs xxx.js时需要加载的文件，也就是说这里会加载用户指定的文件进行解析并运行，紧接着调用iotjs_module_t.load(filename, null);来执行加载操作，看一下load方法的实现： ShadowNode/src/js/module.js：line: 220 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950iotjs_module_t.load = function(id, parent) &#123; if (process.builtin_modules[id]) &#123; iotjs_module_t.curr = id; return Native.require(id); &#125; var module = new iotjs_module_t(id, parent); var modPath = iotjs_module_t.resolveModPath(module.id, module.parent); var cachedModule = iotjs_module_t.cache[modPath]; if (cachedModule) &#123; iotjs_module_t.curr = modPath; return cachedModule.exports; &#125; if (!modPath) &#123; throw new Error('Module not found: ' + id); &#125; var stat = process._loadstat(); var startedAt; if (stat) &#123; startedAt = Date.now(); &#125; module.filename = modPath; module.dirs = [modPath.substring(0, modPath.lastIndexOf('/') + 1)]; iotjs_module_t.cache[modPath] = module; iotjs_module_t.curr = modPath; var ext = modPath.substr(modPath.lastIndexOf('.') + 1); if (ext === 'jsc') &#123; module.compile(true); &#125; else if (ext === 'json') &#123; var source = process.readSource(modPath); module.exports = JSON.parse(source); &#125; else if (ext === 'node') &#123; var native = process.openNativeModule(module.filename); module.exports = native; &#125; else &#123; /** Treat any other file as js file */ module.compile(); &#125; if (stat) &#123; var relPath = modPath.replace(cwd, ''); var consume = Math.floor(Date.now() - startedAt); console.log(`load \"$&#123;relPath&#125;\" $&#123;consume&#125;ms`); &#125; return module.exports;&#125;; 这个方法也是全局require方法所执行的模块加载操作，其中的加载流程和node相同，首先查询是否是内置模块，如果是，则直接返回内置模块，如果不是，则解析模块名，并对缓存进行查询，这里使用绝对路径作为缓存存储的键以避免重复缓存，如果缓存中存在，则直接返回，否则解析模块文件并加载，这里会识别jsc、json、node的文件以使用对应方式进行解析，否则，其他文件都将作为js文件进行解析。最终将module.exports返回。至此，模块就被加载了。 那么问题来了，全局的require函数是怎么就能直接使用了呢？这也是我刚开始看源代码时心中所带的问题。到现在好像也没有看到有相关的操作，那接下就可以分析一下上述代码的compile方法了！以下是compile成员方法的实现：ShadowNode/src/js/module.js：line: 272 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152function _makeRequireFunction(mod) &#123; var Module = mod.constructor; function require(id) &#123; return mod.require(id); &#125; function _resolve(request) &#123; if (!request || typeof request !== 'string') &#123; throw new TypeError('module must be a non-null string'); &#125; if (process.builtin_modules[request]) &#123; return request; &#125; var path = Module.resolveModPath(request, mod); if (!path) &#123; throw new Error('Module not found: ' + request); &#125; return path; &#125; require.resolve = _resolve; require.main = mainModule; require.cache = Module.cache; return require;&#125;iotjs_module_t.prototype.compile = function(snapshot) &#123; var __filename = this.filename; var __dirname = path.dirname(__filename); var fn; if (!snapshot) &#123; fn = process.compile(__filename); &#125; else &#123; fn = process.compileSnapshot(__filename); if (typeof fn !== 'function') throw new TypeError('Invalid snapshot file.'); &#125; var _require = _makeRequireFunction(this); fn.apply(this.exports, [ this.exports, // exports _require, // require this, // module undefined, // native __filename, // __filename __dirname // __dirname ]);&#125;; 这里并没有很复杂的实现，通过process.compile(__filename)和process.compileSnapshot(__filename)创建运行的事例，并组装好require等参数，通过fn.apply(...)将exports、require、module、__filename等我们熟悉的全局函数和对象传入，至此，我们最熟悉的那些模块函数也就可以用了。不过到此为止，好像还缺了点什么，对，还没说ShadowNode模块是怎么寻址的呢！这里我们从iotjs_module_t.resolveModPath(...)方法开始，这个方法在iotjs_module_t.load(...)和require.resolve(...)方法中用于模块寻址： ShadowNode/src/js/module.js：line: 166 123456789101112131415161718192021222324iotjs_module_t.resolveModPath = function(id, parent) &#123; if (parent != null &amp;&amp; id === parent.id) &#123; return false; &#125; var filepath = false; if (id[0] === '/') &#123; filepath = iotjs_module_t._resolveFilepath(id, false); &#125; else if (parent === null) &#123; filepath = iotjs_module_t._resolveFilepath(id, cwd); &#125; else if (id[0] === '.') &#123; var root = path.dirname(parent.filename); filepath = iotjs_module_t._resolveFilepath(id, root); &#125; else &#123; var dirs = iotjs_module_t.resolveDirectories(id, parent); filepath = iotjs_module_t.resolveFilepath(id, dirs); &#125; if (filepath &amp;&amp; (filepath.indexOf('./') &gt; 0 || filepath.indexOf('../') &gt; 0)) &#123; return iotjs_module_t.normalizePath(filepath); &#125; return filepath;&#125;; parent是指调用目标模块的模块，也属于module的实例，而后根据模块路径的形式和传入的parent值指定模块寻址的起点，比如当parent === null时传入cwd作为寻址起点，也就是脚本运行的当前目录。接下来是iotjs_module_t._resolveFilepath(...)：ShadowNode/src/js/module.js：line: 129 1234567891011121314151617181920212223242526272829303132333435iotjs_module_t._resolveFilepath = function(id, root, ext_index) &#123; var modulePath = root ? path.join(root, id) : id; var filepath; var exts = ['.js', '.json', '.node']; if (ext_index === undefined) &#123; ext_index = 0; &#125; // id[.ext] if (filepath = tryPath(modulePath, exts[ext_index])) &#123; return filepath; &#125; // id/index[.ext] if (filepath = tryPath(modulePath + '/index', exts[ext_index])) &#123; return filepath; &#125; // 3. package path id/ var jsonpath = modulePath + '/package.json'; filepath = iotjs_module_t.tryPath(jsonpath); if (filepath) &#123; var pkgSrc = process.readSource(jsonpath); var pkgMainFile = JSON.parse(pkgSrc).main; // pkgmain[.ext] if (filepath = tryPath(modulePath + '/' + pkgMainFile, exts[ext_index])) &#123; return filepath; &#125; &#125; ext_index++; if (ext_index &lt; exts.length) &#123; return iotjs_module_t._resolveFilepath(id, root, ext_index); &#125;&#125;; 此函数将目标模块的路径进行组合并尝试读取模块文件，在这里会识别js、json、node 三种格式的文件以及index.*默认文件，若读取失败，则尝试读取package.json中依赖的模块，最终返回完整的模块路径。后续对模块地址进行整理即返回，模块的寻址也就结束了。 以上内容描述了ShadowNode中module模块的实现过程，包括全局对象的构建、模块寻址、缓存优化等，但其中有一些细节比如process.compile(...)如何对模块文件进行编译以及snapshot构建等问题没有深入论述，后续随着我参与项目构建的深入我还会继续详解。 作为一个开源爱好者，也是一名noder，我对ShadowNode的关注由来已久，但真正参与构建也就近两个月的事情，一直以来我对这个项目保留了一些疑问和不解，对此我也特地和ShadowNode作者@yorkie有过一次详谈，一方面从性能角度来看，js并不优良的性能以及它的运行环境对系统资源的巨大消耗决定了其绝对不是构建嵌入式设备应用的绝佳选择，开源社区对类似运行时的diss也基本集中在这方面；另一方面从生态的角度来看，虽然js的生态非常完备，尤其是在node和npm崛起之后，但嵌入式设备应用开发本身也并不是一个巨大的需求，因此对于构建这样一个类node且运行于嵌入式设备的运行时是否具有现实意义，我一直是存疑的。对此，yorkie也给了解答，构建ShadowNode的动机很简单，其实就是看中js本身所具有的巨大生态支撑，而其他并没有太多考虑（事实上也不值得考虑太多），yorkie还用了Android的例子，选择Java作为其开发语言并不是看中Java的性能，而是其强大的生态。确实，这没毛病，而且最终Android也反过去助长了Java生态的增长。尽管这一点也并没有绝对说服我，但ShadowNode的最终目标在于社区建设和生态构建，且对未来发展有更多的憧憬与期待而非该技术本身这一点，也还是令我信服的。 以上是我对ShadowNode实现的简单阐述及我个人粗浅的看法与理解，有错误或遗漏的部分欢迎指正 : ) 2018-12-20","permalink":"https://txiaozhe.github.io/2018/12/20/snode-module/","photos":[]},{"tags":[{"name":"Life","slug":"Life","permalink":"https://txiaozhe.github.io/tags/Life/"},{"name":"Job","slug":"Job","permalink":"https://txiaozhe.github.io/tags/Job/"}],"title":"在西溪湿地做景区管理员","date":"2018/12/18","text":"西溪湿地风光","permalink":"https://txiaozhe.github.io/2018/12/18/xixi/","photos":[]},{"tags":[{"name":"Job","slug":"Job","permalink":"https://txiaozhe.github.io/tags/Job/"},{"name":"Mac","slug":"Mac","permalink":"https://txiaozhe.github.io/tags/Mac/"},{"name":"Tech","slug":"Tech","permalink":"https://txiaozhe.github.io/tags/Tech/"}],"title":"更改Bash版本引发的Mac事故","date":"2018/08/22","text":"之前参与了CockroachDB的文档翻译，总觉得不够，希望能参与到项目的开发中。于是查看各种文档，开发指南。幸好CockroachDB 官方有完整的开发指导，于是我就按照开发指引来进行环境的搭建，使用的电脑是2017款MacBook Pro，OSX 10.13.3，8Gb，Core i5。 项目开发对环境有很多要求，比如C++需要支持11版本，Go版本需要1.9+等等，其中还有一条要求，Bash的版本需要在 4+，我们都知道，mac默认的bash是3.2版本的，因此需要进行升级。升级的方法是网上查的，使用brew 进行安装： 1$ brew install bash 但是可执行文件会被安装到 /usr/local/Cellar/bash 中，而真正的 bash 仍在 /bin/bash 中，为了方便会用4+版本的bash，需要对命令指向进行改动。 按照教程，因为Mac系统引入了sip机制禁止更改系统目录的权限，因此需要先关闭sip机制再进行修改： 重启OSX，启动时快速按住 cmd + R 出现系统恢复界面后，标题栏选择 Utilities - menu ，进入Terminal 输入 csrutil disable 关闭SIP( csrutil enable 为打开SIP) 重启Mac 此时Mac正常启动，进入正常使用的界面，输入以下命令修改 bash 指向： 12$ sudo mv /bin/bash /bin/bash.origin$ sudo ln -s /usr/local/Cellar/bash /bin/bash 修改完成后输入： 1$ bash --version 出现 12GNU bash, version 4.4.23(1)-release (x86_64-apple-darwin17.5.0)... 大功告成，bash升级成功，于是重启电脑，再次按 cmd + R 进入恢复界面，输入 csrutil enable 打开SIP，再次重启。 此时却没有顺利启动起来，一直卡在登录界面的进度条那里，强制关机、重启也不管用了。查了各种资料，各种方式重启也都不顺利，最后准备重装系统，可惜此时发现系统却没有备份，重装的话有可能丢失数据（这里推荐大家一定要定时及时地进行系统备份，否则到这种时候只有哭的份了），看来也没办法了，强制重装吧。 这个时候突然想到Mac恢复界面是可以使用Terminal的，要不把bash指向改回去试试。于是死马当活马医，重启Mac，再次按 cmd + R 进入恢复界面，进入Terminal： 12$ sudo mv &#x2F;bin&#x2F;bash.origin &#x2F;bin&#x2F;bash$ sudo unlink &#x2F;bin&#x2F;bash 再次重启，竟然复活了，系统完好无损，简直惊险。 到这里，以为bash就这样无法升级了，那也就跟CockroachDB开发无缘了，不过当我在Termina中输入： 1$ bash --version 再次出现： 12GNU bash, version 4.4.23(1)-release (x86_64-apple-darwin17.5.0)... 发现bash已经被改好了，此时算是有惊无险而且结果也是令人满意的。 最后总结两点： 不要随随便便更改系统配置 一定要备份 一定要备份 一定要备份","permalink":"https://txiaozhe.github.io/2018/08/22/bash-mac-error/","photos":[]},{"tags":[{"name":"CockroachDB","slug":"CockroachDB","permalink":"https://txiaozhe.github.io/tags/CockroachDB/"},{"name":"Kubernetes","slug":"Kubernetes","permalink":"https://txiaozhe.github.io/tags/Kubernetes/"}],"title":"在 Kubernetes 集群中运行 CockroachDB","date":"2018/06/10","text":"原文 作者：Alex Robinson 2016年10月11日 [使用说明于2017年1月4日更新] 在Cockroach Labs，我们一直在为更简单地实现用户数据在灾难性错误的情况下保持安全和可用而努力。然而，如果你曾经在是生产环境中负责部署和运维，你就会发现使系统具备高可靠性远不止启动几个进程这么简单，这对于CockroachDB这类具有极强生命力的应用来说也是如此。于是，Kubernetes就有了用武之地。 Kubernetes是一个开源的系统，用于自动化部署，集群扩缩容和容器化应用的管理。这里的 ”容器化“ 即Docker的应用。Kubernetes提供了各种各样的服务，用来实现保持应用程序的正常运行，应用程序复制和更新回滚以及健康检查和日志收集。 如果你熟悉CockroachDB，你就知道它处理了在面对各种故障时以一致的方式复制数据的过程中所有复杂的细节。通过在Kubernetes中运行CockroachDB，我们可以将其内置的副本和生存性模块与Kubernetes的进程管理器匹配，创建一个真正使数据变得简单的高可用系统。 在Kubernetes中进行状态管理如果你有一些Kubernetes的使用经验，你可能会有所质疑，数据库要运行在一个系统上，这个系统的历史中却没有为有状态的集群化应用提供一个很好管理服务。确实，Kubernetes早期阶段主要的目标是无状态的应用（无需管理它们自己的持久数据），但是，Kubernetes背后的团队在今年已经开始致力于以StatefulSet的形式为有状态的应用构建一流的支持。 通常来说，当一个Kubernetes pod（包含经编排的一个或多个容器的运行组）消亡时，它将被一个新的pod所取代，新的pod会包含一个新的标识符，新的IP地址以及主机名。但是，无论这个pod重启多少次甚至改变底层的主机，StatefulSet都可确保每个副本拥有它自己稳定的标识符（通过DNS解析）。这对于CockroachDB来说是很有意义的，因为这意味着每当pod被新副本取代时，我们不再需要像对待集群中的新节点那样对待这个pod，否则这会导致大量的数据复制。这对于高效支持我们的一致性协议和分布式事务是很重要的。 在Kubernetes这样的编排系统中运行像CockroachDB这样的数据库，另一个更明显的问题是如何找出每一个副本的数据存在的位置。不同的存储方式，其相应解决方案的成熟度不同。Kubernetes很早就对‘PersistentVolumes’有了很好的支持，也就是可以挂载在Kubernetes任意节点上的远程磁盘。这是一种很好的策略因为它允许一个副本在不丢失任何数据的情况下迁移。然而，正因为这些数据是远程的（且常常在后台被复制，比如EC2上的EBS卷和Google Compute Engine上的持久卷），这意味着相比于使用本地磁盘，这种方式存在明显的延迟开销。 像CockroachDB这样一个云生和集群化的数据库来说，偶尔出现单台机器上的数据丢失的情况，一点问题都没有，因为它能探测到机器上数据副本不足，从而相应添加副本。正因如此，理想情况下为每个副本使用本地磁盘可以降低延迟。然而，由于一些原因（这些问题已经在1.6release版本中经过了严肃的讨论），Kubernetes目前还不支持StatefulSets使用本地磁盘。在此期间，远程持久卷已经能满足我们的需求。 实现细节：在Kubernetes中运行CockroachDB创建一个Kubernetes集群创建一个Kubernetes集群有很多种不同的方式。为了简单起见我们将使用Container Engine，这在其他环境下也是可行的。例如，参照我们的文档有关如果在本地Minikube中运行或参照Kubernetes 的文档在AWS中创建集群。如果你安装了gcloud，你可以通过运行以下命令来创建集群： 1$ gcloud container clusters create cockroachdb-cluster 快速启动CockroachDBKubernetes的配置使用YAML配置文件进行管理，CockroachDB的配置也不例外。我们可以使用以下配置创建一个集群，其中的注释解释了我们的操作。首先，从我们的Github 仓库中复制名叫cockroachdb-statefulset.yaml的配置文件。这个文件定义了将被创建的Kubernetes资源，包括快速启动CockroachDB 容器的StatefulSet对象并将其连接至持久卷。 然后，创建这些资源，如下（如果你使用Minikube，你可能首先需要手动配置持久卷）。稍后，你将看到在集群中运行的3个副本和一些服务。刚开始，因为副本还没有全部启动，可能只显示一部分的副本。这是正常的，因为StatefulSets会从第一个开始逐个创建副本： 1$ kubectl create -f cockroachdb-statefulset.yaml service “cockroachdb-public” createdservice “cockroachdb” createdpoddisruptionbudget “cockroachdb-budget” createdstatefulset “cockroachdb” created 1$ kubectl get services cockroachdb None 26257/TCP,8080/TCP 4scockroachdb-public 10.0.0.85 26257/TCP,8080/TCP 4skubernetes 10.0.0.1 443/TCP 1h 1$ kubectl get pods NAME READY STATUS RESTARTS AGEcockroachdb-0 1/1 Running 0 29scockroachdb-1 0/1 Running 0 9s 1$ kubectl get pods NAME READY STATUS RESTARTS AGEcockroachdb-0 1/1 Running 0 1mcockroachdb-1 1/1 Running 0 41scockroachdb-2 1/1 Running 0 21s 如果你想看看这个过程中发生了什么，你可以运行kubectl logs cockroachdb-0查看其中一个pod的日志。 使用CockroachDB集群一旦你的集群开始运行了，你一定会想去尝试它。通过Kubernetes打开一个SQL shell，你可以运行一个一次性的pod，并使用cockroachdb-public作为hostname来访问CockroachDB集群。Kubernetes将会自动均衡地将连接分配至健康的CockroachDB实例。 1$ kubectl run cockroachdb -it --image&#x3D;cockroachdb&#x2F;cockroach --rm --restart&#x3D;Never -- sql --insecure --host&#x3D;cockroachdb-public 等待cockroachdb运行成功，此时状态为Pending，pod ready状态为 false 输入如下命令： 12345678910111213root@cockroachdb-public:26257&gt; CREATE DATABASE bank;CREATE DATABASEroot@cockroachdb-public:26257&gt; CREATE TABLE bank.accounts (id INT PRIMARY KEY, balance DECIMAL);CREATE TABLEroot@cockroachdb-public:26257&gt; INSERT INTO bank.accounts VALUES (1234, 10000.50);INSERT 1root@cockroachdb-public:26257&gt; SELECT * FROM bank.accounts;+------+-------------+| id | balance |+------+-------------+| 1234 | 10000.5 |+------+----------+(1 row) 查看管理页面如果你想查看集群的行为信息，你可以通过将你本地机器的端口映射到其中一个pods拉取CockroachDB管理UI： 1$ kubectl port-forward cockroachdb-0 8080 运行了这个命令，你就可以在浏览器中输入http://localhost:8080/来访问管理UI了。 模拟节点故障如果你想测试集群的弹性，你可以尝试在通过SQL shell访问集群的同时，新起一个终端运行类似于kubectl delete pod cockroachdb-3的命令来杀掉一些容器。如果你碰巧删除了你的shell正在操作的实例，你可能偶尔会遇到 bad connection 的错误，但是重试查询操作依然会生效。这些被杀掉的容器将会通过StatefulSet 管理器被重新创建，就像机器在生产环境中宕机一样。 如果你想测试集群中数据的持久性，你也可以尝试一次性删除所有的pod并确保当它们恢复时能正确地从各自的持久化卷中启动。要实现这一点，可以通过运行kubectl delete pod –selector app=cockroachdb以删除所有标签为app=cockroachdb的pod，其中包括来自我们StatefulSet中的pod。所有的pod恢复的过程会花费一点时间（就像创建它们的时候一样），但是一旦它们重启并再次运行，你运行SQL语句时就应该得到相同的结果。 缩放CockroachDB集群Kubernetes使得按需缩放集群变得简单。如果你想为集群添加新的副本，你需要做的就是调整StatefulSet，如下所示： 1$ kubectl scale statefulset cockroachdb --replicas=4 关闭CockroachDB集群如果你想清理所有我们创建的资源，可以通过一条命令，这要归功于我们为所有资源添加的labels: 1$ kubectl delete statefulsets,pods,persistentvolumes,persistentvolumeclaims,services,poddisruptionbudget -l app=cockroachdb 或者，你也可以关闭整个Kubernetes集群： 1$ gcloud container clusters delete cockroachdb-cluster 鉴于目前CockroachDB尚未成熟地产品化，我们现在不建议将此设置应用到关键任务的数据中，但是，但是你仍然可以在机器上做很多事，比如： 使用众多支持CockroachDB 集群的客户端中的一个来开发应用。 修改集群初始化的方式以便在节点之间使用证书进行加密。 在云主机或裸机上而不是在容器引擎中用不同的持久卷起一个集群。 利用我们在CockroachDB StatefulSet中提示的优势搭建Prometheus来监控集群内的CockroachDB。 将构建特征的请求、问题或改进建议提交给CockroachDB、Kubernetes 文档或它的核心数据库。 参考在我们的文档或Github 仓库中可以找到在Kubernetes中运行CockroachDB的最新配置文件等更多信息。","permalink":"https://txiaozhe.github.io/2018/06/10/run-cockroachdb-in-kubernetes/","photos":[]},{"tags":[{"name":"CockroachDB","slug":"CockroachDB","permalink":"https://txiaozhe.github.io/tags/CockroachDB/"},{"name":"Schema","slug":"Schema","permalink":"https://txiaozhe.github.io/tags/Schema/"}],"title":"CockroachDB 是如何让在线Schema Change成为可能的","date":"2018/05/24","text":"我经常需要更改表结构，其中主要是为表添加列。当然这用alter命令很容易就能实现，但是，目前我的表已经达到40,000,000行之多且还在不断地增长，这使得执行alter命令往往需要个把小时。因为我用的是亚马逊的RDS服务，所以我不能用主从的策略来实现。因此我在思考能否做到在最小化的宕机时间条件下做到这一点。当然我也不介意有用户愿意花费几小时甚至几天的时间来进行这样的操作…… ——— 摘自 Stack Overflow 2010年8月26日 serverfault ​ 以上这条提问是在2010年发布的，但是关于进行这种操作问题的焦虑至今却依然存在。 ​ 我们在设计CockroachDB表结构更改引擎的时候总想把它做得更好以提供一个简单的修改表结构的方式(比如只要运行ALTER TABLE命令就可以)使得应用不需要承担宕机带来的任何负面后果。我们也希望更改表结构是CockroachDB的一项内置功能而不需要任何外界工具、资源或特定的操作步骤来支持且对应用程序的读写没有任何影响。 ​ 我将用以下的篇幅来解释我们在线更改表结构方案的机制并讨论在不宕机的前提下对结构元素(如列和索引)的更改。 我们做了什么​ 更改表结构通常涉及到更改结构本身和随着结构的更改而增加或删除的数据关系，而分布式数据库的两个基本特性使得这一点实现起来并不那么容易： 高性能：为了优化数据库性能，表结构必须缓存跨库节点，而维护分布式缓存的一致性往往是非常困难的 大表：分布式数据库中的表往往非常巨大，与表结构更改相关的任何表数据的回填或删除都将花费一定时间，要在不禁用数据库访问的前提下实现这一点也非常困难 ​ 对于第一个问题，我们给出的解决方案包括使用版本化的结构，并允许在旧版本结构仍在使用的情况下发布新的结构和对大表支持在不加锁的情况下回填(或删除)表数据。这个解决方案由谷歌的F1团队在工作中总结得出。 创建安全结构​ 和表结构元素(可以是索引或列，但在本文的剩余部分中我们将着重关注索引)相关联的数据都可以通过SQL DML命令删除或读写(比如 INSERT, UPDATE, DELETE, SELECT)。CockroachDB使用的策略是建立新索引时逐个而非同时地对其赋予以上命令描述的删除和读写权限。 因此，建立一个新索引需遵循以下步骤： 赋予删除权限 赋予写权限 回填索引数据 赋予读权限 ​ 在新的结构中，新授予的权限将与旧版本中已赋予的权限一起被授予。为了保证正确性，一种新的权限在只有当整个集群都使用包含所有已赋予权限的结构时的情况下才能被赋予，因此，整个过程将在每一步执行前暂停并允许在下一项权限赋予前将已赋予的权限应用到整个集群。 删除索引时也同样需要遵循相应的步骤： 吊销读权限 吊销写权限 清除索引数据 吊销删除权限 ​ 同样，一种操作权限被吊销时也需确保整个集群对已赋予的权限进行了同样的操作。 删除操作权限：避免虚假索引条目​ 当某位置建立了DELETE_ONLY状态的索引时即赋予这种权限，具有这种权限的SQL DML命令具有自我约束的特性： DELETE：这种删除操作将完全作用于该索引所涉及到的行和基础索引数据 UPDATE：会删除旧的索引条目，并限制自身不会写入新的索引条目 INSERT 和 SELECT 会忽略索引 ​ 在下一阶段中对索引被赋予写权限的节点将信任整个集群使用索引的删除权限。也就是说，当节点收到一个INSERT命令需要为一行数据插入索引条目时，另一个只拥有删除权限的节点在收到针对相同行的DELETE命令时会准确地删除该行的索引，这个索引将避免因悬空索引而出错。 ​ 另外，当删除索引时，相关的索引数据也仅在写入权限被集群回收后才会被删除，并且也只有当集群拥有删除能力时才允许其进行安全的删除操作。 写入权限：避免丢失索引条目​ 当某位置建立了WRITE_AND_DELETE_ONLY状态的索引时随即赋予这种同时具有删除和写入的权限： INSERT，UPDATE和 DELETE 命令都正常运行，并按需添加或删除索引项 SELECT 命令需要读取权限因而会忽略索引 ​ 索引回填仅在整个集群都可写入时才可以运行。在回填过程中，任何节点上接收到的 INSERT 命令都将创建一个带有合法索引项的新行，并且不依赖单独的回填过程来为该行创建索引项。如此一来，可以保证直整个过程都不会丢失索引项。 读权限​ 最后一个权限是通过索引激活来赋予的，并且可以被所有命令完全使用。 快速的表结构迭代​ 在表结构更改的每一个阶段中都将允许整个集群的表结构向最新版本看齐。一般的表结构缓存机制都使用5分钟的存活时间，这也导致在修改进程信任最新版本的表结构是独有的且操作能力被完全赋予或吊销之前被强制要求等待几分钟。在CockroachDB中，我们开发了表结构版本的租约来加速集群表结构更新到最新版本以加快表结构更新的进程。 ​ 当要对表进行SQL DML命令操作时，运行该命令的节点会获取一个具有有效时间(以分钟为单位)的读取租约。被更改了的表结构版本被激活的消息会被广播到整个集群以通知节点更新到新的版本并主动释放旧版本的租约，此时如果一些不健康的节点未能主动释放，迭代机制将等待租约的过期以及延期迭代。 ​ 租约机制通过遵循以下两个规则使得表结构更改策略更简单： 最新的结构版本才可以签发新租约 有效的租约只存在于最新的两个版本之内 有关表租约更详细的讨论请在我们的Github 库的文档中查看。 准确可靠的表结构迭代​ 表结构的更改由节点执行的相关SQL命令来引导完成，这个过程往往耗费较长时间，假如过程中节点宕机则需要重启整个过程。每个节点也都会运行一个能执行任何不完整的结构更改过程的协程，在更改结构过程运行前，这个协程会获取相关表的一个独有的写入租约，这也是唯一可以引导更改成功的许可证。 小结​ 在线表结构的更改操作在CockroachDB中非常容易实现并且安全、快速、可靠。改变是不可避免的，而现在你再也不必担心了！ ​ 在此感谢谷歌F1团队发布的在线表结构更改的类似实现，我们从中也获得了很多灵感。","permalink":"https://txiaozhe.github.io/2018/05/24/schema-change/","photos":[]},{"tags":[{"name":"GitHub","slug":"GitHub","permalink":"https://txiaozhe.github.io/tags/GitHub/"}],"title":"记一次 GitHub 的惊险历程","date":"2017/07/27","text":"今天得空重新部署了一下GitHub博客，换了新的主题和布局，感觉一切都焕然一新。 ​ 我原本是有一个GitHub博客的，第一次部署花了很长时间，各种奇怪的错误，各种坑，但最后也部署成功了，而且因为做过一段时间前端，所以除了框架里给的主题，也按照自己的想法换了一些风格，当时是很有成就感的。也断断续续地往上添了一些内容，Docker、移动端、前端开发等。但后来又来了新项目，时间也逐渐被工作占满，也渐渐地遗忘还有一个博客孤单的跑在GitHub上，直到前几天…… ​ 就在这周二，也就是2017年7月25日，早上，我和往常一样来到公司，打开电脑，因为公司内部所有项目都是基于GitHub平台进行管理的，而且有几个项目还是交由我来管理的，因此习惯性地点开GitHub主页查看项目进度。但是奇怪，平常很快就能登录的GitHub这次却怎么也无法登录，因为用的是Chrome浏览器因此能记住密码，连续点了几次登录依然无法成功，接着又开始怀疑是密码错误，反复试了密码都提示账号或密码错误。这时候突然有人喊：你的那个商城的项目不见了！！！我顿时慌了，查看另外几个项目也都消失了，最后在GitHub搜索框里搜索我的用户名也没有结果，紧接着查看了一下与GitHub账户绑定的Gmail，就看到了这样一封邮件： This email is to confirm that you’ve deleted your account ‘Txiaozhe’ from GitHub. Your repositories and content have been deleted from the system. If you were on a paid plan, you will not be billed again. We’re sorry to see you go. You can reply directly to this email if you have any questions or feedback, we’d love to hear from you. 我的天，我的GitHub竟然被删除了！！！从邮件里看还是被我自己删除的！！！当时第一反应就是GitHub账户被黑了，一定是某人登陆了我的账户并删除账户。这个杀千刀的。当时已经是上班时间，大家基本都到了，得知这个消息后突然都变得很恐慌，连忙查看自己账户是否也有问题。而彼时彼刻，我的内心更是心痛万分，2015年申请的GitHub账户，到现在已经两年多了，项目数、提交数、star数都有一点积累，特别是最近一年，而这一次被删除意味着这些努力都白费了，辛辛苦苦写的代码，本地也只备份了一小部分，那些没备份的都消失了。 ​ 等心情平复了一些，慢慢地也就接受了现实，想着其实之前写的代码里也是有很多垃圾代码的，正好趁着这次机会重构一下，同时也总结之前做的事。重新申请了GitHub账户，把之前本地备份过的代码也都重新上传，看着新的账户里的内容逐渐丰富起来，也算是有了一点点安慰。同时，为了防范再次出现这类事件，公司要求所有人的GitHub账户都必须设置二步验证，阅读过这篇博客的读者也可以尝试设置二步验证以加强账户安全。 ​ 第二天的时候，事情突然有了转机。有一个同事在搜索我的用户名的时候偶然间发现我原来的用户名又出现了，紧接着就确认，我的账户又恢复了！我重新登陆了一下原来的账户，果然又能登陆了，而且里面的项目都恢复了！这算是惊喜吗？我和同事们开玩笑，人生的大起大落也不过如此！再看看Gmail，突然又多了几封邮件，打开看看，原来是GitHub的工作人员发来的，邮件就不展示了，主要内容就是各种道歉，原来是他们的员工操作失误将我的代码库删除了，而且因祸得福，为了弥补我，他们打算赠送我一件GitHub主题的T恤和6个月的私有库账户权限，并很及时地恢复了账户中的错误，在此也非常感谢GitHub的工作人员 Chris 、Michael 和 Jonathan Hoyt 帮我解决了问题。 ​ 过了3天了，回想起来从最开始的痛心，紧接着平复到最后得到补偿竟然还有点惊喜，整个历程可谓跌宕起伏。最后不足的是其他都恢复了，但还有部分提交记录和GitHub博客没恢复，提交记录基本认命了，但博客还是可以重新打造的，也算是脱胎换骨了，仅以记录了这次事件的文章作为新博客的开篇，也算是留个纪念了！","permalink":"https://txiaozhe.github.io/2017/07/27/github-adjective/","photos":[]},{"tags":[{"name":"OAuth","slug":"OAuth","permalink":"https://txiaozhe.github.io/tags/OAuth/"},{"name":"JWT","slug":"JWT","permalink":"https://txiaozhe.github.io/tags/JWT/"}],"title":"常用鉴权方式和JWT简介","date":"2017/07/24","text":"常用的认证HTTP Basic Auth 每次请求时都提供用户名和密码，是最简单的认证方式 有把用户名密码暴露给第三方的风险，因此生产环境下越来越少地被使用 OAuth（开放授权） 允许第三方应用访问该用户在某一web服务器上存储的私密的资源，无需将用户名密码提供给第三方 用户提供一个令牌而非用户名密码来访问特定服务提供者的数据 适用于个人消费类的互联网产品，如社交App（微信），但不适合拥有自有认证权限管理的企业应用 Cookie Auth &amp; Token Auth Token Auth的优点 支持跨域访问：Cookie不支持跨域访问，当用户认证信息通过HTTP头传输时Token允许跨域访问 无状态：Token自身包含了所有登录用户的信息，只需要在客户端存储相关信息而不需要在服务端存储 更适用于CDN（内容分发网络）：可以通过内容分发网络请求服务端的所有资料 去耦：不需要绑定到特定的身份验证方案，可在任何地方生成Token 更适用于移动平台：原生平台不支持cookie，因此适合采用Token 无需考虑CSRF（跨站请求伪造）：因不依赖cookie，因此无需考虑该安全问题 性能：一次网络往返时间（通过数据库查询session信息）比做一次Token验证和解析要费时的多 标准化库：可采用JWT标准的库，生态支持良好 基于jwt的Token认证机制实现JWT 的组成Token是一个字符串，由三部分组成：头部、载荷、签名 载荷(Payload)： 1234567891011&#123; \"iss\": \"Online JWT Builder\", \"iat\": 1416797419, \"exp\": 1448333419, \"aud\": \"www.example.com\", \"sub\": \"jrocket@example.com\", \"GivenName\": \"Johnny\", \"Surname\": \"Rocket\", \"Email\": \"jrocket@example.com\", \"Role\": [ \"Manager\", \"Project Administrator\" ]&#125; iss：JWT签发者，可选 sub：JWT面向的用户，可选 aud：接收该JWT的一方，可选 exp（expires）：过期时间，时间戳，可选 iat（issued at）：签发时间，可选 将上面的json进行base64编码得到一下字符串，称为Payload： 1eyJpc3MiOiJKb2huIFd1IEpXVCIsImlhdCI6MTQ0MTU5MzUwMiwiZXhwIjoxNDQxNTk0NzIyLCJhdWQiOiJ3d3cuZXhhbXBsZS5jb20iLCJzdWIiOiJqcm9ja2V0QGV4YW1wbGUuY29tIiwiZnJvbV91c2VyIjoiQiIsInRhcmdldF91c2VyIjoiQSJ9 Base64是一种基于64个可打印字符来表示二进制数据的表示方法。由于2的6次方等于64，所以每6个比特为一个单元，对应某个可打印字符。三个字节有24个比特，对应于4个Base64单元，即3个字节需要用4个可打印字符来表示 头部(Header)：描述该jwt最基本的信息 1234&#123; \"typ\": \"JWT\", \"alg\": \"HS256\"&#125; alg：签名算法（必选，其他都是可选） typ: 类型 （如果是 JWT 那么就带有一个值 JWT） *kid: * 密钥 ID cty: 内容类型 jku: JWK 指定 URL jwk: JSON 网络值 x5u: X.509 URL *x5c: * X.509 证书链 x5t: X.509 证书 SHA-1 指纹 x5t#S256: X.509 证书 SHA-256 指纹 crit: 临界值 将该头部也进行base64转换，得到如下字符串： 1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9 签名（Signature）： 将上面的两个编码后的字符串都用句号.连接在一起（Header在前），就形成了: 1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJKb2huIFd1IEpXVCIsImlhdCI6MTQ0MTU5MzUwMiwiZXhwIjoxNDQxNTk0NzIyLCJhdWQiOiJ3d3cuZXhhbXBsZS5jb20iLCJzdWIiOiJqcm9ja2V0QGV4YW1wbGUuY29tIiwiZnJvbV91c2VyIjoiQiIsInRhcmdldF91c2VyIjoiQSJ9 最后，将上面拼接完的字符串用HS256算法进行加密。在加密的时候，我们还需要提供一个密钥（secret）。比如用mystar作为密钥，加密后的内容: 1rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM 最终的Token： 1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJKb2huIFd1IEpXVCIsImlhdCI6MTQ0MTU5MzUwMiwiZXhwIjoxNDQxNTk0NzIyLCJhdWQiOiJ3d3cuZXhhbXBsZS5jb20iLCJzdWIiOiJqcm9ja2V0QGV4YW1wbGUuY29tIiwiZnJvbV91c2VyIjoiQiIsInRhcmdldF91c2VyIjoiQSJ9.rSWamyAYwuHCo7IFAgd1oRpSP7nzL7BF5t7ItqpKViM Token认证过程： 第一次登录，用户从浏览器输入用户名/密码，提交后到服务器的登录处理的Login Action层 Login Action调用认证服务进行用户名密码认证，如果认证通过，Login Action层调用用户信息服务获取用户信息（包括完整的用户信息及对应权限信息） 返回用户信息后，Login Action从配置文件中获取Token签名生成的秘钥信息，进行Token的生成； 生成Token的过程中可以调用第三方的JWT Lib生成签名后的JWT数据 完成JWT数据签名后，将其设置到COOKIE对象中，并重定向到首页，完成登录过程 请求认证 基于Token的认证机制会在每一次请求中都带上完成签名的Token信息，这个Token信息可能在COOKIE中，也可能在HTTP的Authorization头中 客户端（APP客户端或浏览器）通过GET或POST请求访问资源 认证服务作为一个Middleware HOOK 对请求进行拦截，首先在cookie中查找Token信息，如果没有找到，则在HTTP Authorization Head中查找 如果找到Token信息，则根据配置文件中的签名加密秘钥调用JWT Lib对Token信息进行解密和解码 完成解码并验证签名通过后，对Token中的exp、nbf、aud等信息进行验证 全部通过后，根据获取的用户的角色权限信息，进行对请求的资源的权限逻辑判断 如果权限逻辑判断通过则通过Response返回给客户端 使用Token Oauth 需要注意的地方 一个Token就是一些信息的集合，因此可以在Token中包含足够多的信息，以便在后续请求中减少查询数据库的几率，其中的机密信息应加密后再存入 服务端需要对cookie和HTTP Authrorization Header进行Token信息的检查，因此可以用一套token认证代码来面对浏览器类客户端和非浏览器类客户端 因为token是被签名的，所以我们可以认为一个可以解码认证通过的token是由我们系统发放的，其中带的信息是合法有效的 通过JWT登出因为没有 session 数据存储在服务端所以不能再通过破坏 session 来注销用户。因此登出成为了客户端的职责 - 一旦客户丢失了令牌不能再被授权，就可以被认为是登出了","permalink":"https://txiaozhe.github.io/2017/07/24/auth/","photos":[]},{"tags":[{"name":"Life","slug":"Life","permalink":"https://txiaozhe.github.io/tags/Life/"}],"title":"大学中的五件事","date":"2014/05/17","text":"不知道是为什么，最近有很多人来和我抱怨说生活无趣，无所事事，未来渺茫，诸如此类。或许是在这个年龄段的人都会有的心理吧，想想自己也曾经有的心里的变动，便能理解一些。在开导之余，我也在思考其中的意味，简单地总结了几件事来说说。 第一件事：关于生活 简单的说，这个应该是很多大学生的通病吧，就我自己而言，曾经也有这样的想法，那应该是在大学的初期。记得刚进大学那时，相信很多人和我面对的形势都一样，同样是刚进入大学时的好奇感，进入新的地区时的新鲜感以及对高三一直以来的繁重任务的解脱并且获得自由时的欣喜的情感夹杂等等，想必那时肯定是抱着极大的希冀和抱负走进大学校园的。第一件可以令人感到或许施展才华与抱负的机会来了的事便是各种社团的招新，相信也都和我一样面对那些社团就像走进了大观园，蠢蠢欲动又不知选择何者，只能凭着自己的理解、前辈的经验以及宣传的说辞来做出判断，然后做出选择。渐渐地，社团活动的开展成为了大学生活中很重要的一部分，加上有些同学并不繁重的课程，或许，我可暂将那时理解成是最有成就感的时期吧。 想必在后期也会有这样一个时期，大学与高中不同，大学则更像是一个社会，面对一些事情难免会有力不从心的经历，渐渐地，你是否感觉你的心已经枯竭，你的生活在没有事情可做的时候就变得浑浑噩噩了呢。我有时候想，或许，大学就是一个这样来磨砺我们心智的地方，在这里，我们可以选择不成功，但是我们无法选择不成长。在这里，我想分享一下我自己的生活的心得，希望能对那些感觉在大学里没事做的人有一点点帮助吧。 每当有人来和我抱怨感觉没事做，生活碌碌无为的时候，我就和他们说：那你就去找点事做，实在找不着，那就去睡觉吧，不要觉得是虚度，就算实在没有理由，你也要把这件事当做是为了把宿舍本睡够了。每听到一些抱怨生活的语气，或者是碰到一些不开心的心情来向我诉说，我也总能想起自己的经历，或许我也能把这些看透了，或者我是欺骗自己把这些看透了，这些都不重要，重要的是要对生活充满信心，充满信念，我常常能想起招之的一句话，“要充满信心”，记得这是招之在考试之前经常说的一句话，可能与招之其他的名言比起来并没有多少起眼，但我想，在这个场合，说这句话是再合适不过了。简单的一句话就概括了我们面对生活时应该有的最基本的情操。我在学校里的生活可能也算比较枯燥的吧，但是，或许只要我不这么想，那就是有意义的，或许也像我的舍友评价的那样：你知不知道你活得很有情趣的。我喜欢这句话，我喜欢活得有情趣。相信在我的同学之中，再没有人会比我的我的生活环境更差的了，全国第一的雾霾让人望而却步，八人间的宿舍仍旧沿袭着脏乱差的传统，每周46节的课再加上作业同样也让人有感于高三的生活，但是，我会好好地过我的生活。我会在空闲之余做一些我喜欢的事，和同学一起写写字，聊聊天，可以尽量散漫些；有空的时候一个人出去散步，我喜欢一个人走，安安静静，虽然一路上总是一对一对的，我想，只要保持内心的平静就好了；晚上我都会去图书馆坐一坐，想出来的时候就出来，不必强求，走在路上，听着清新淡雅的钢琴曲，穿过马路、走过天桥，等放完了一首罗密欧和朱丽叶与一首梦中的婚礼就回到宿舍了，一天也就这样度过，不必遗憾，这也是一种生活。 所以，不必总是抱怨生活无趣，不必抱怨生活没有事情可做，听我的，找一件你喜欢的想做的事情来做，如果实在没事做那就睡觉吧，精神养好了，一切，就都好了！ 对于我本人来说，我不喜欢的两件事，一是熬夜，一是看恐怖片。可能是大学生的通病吧，想必很少有大学生晚上会在11点之前睡觉，哪怕过了十一点以后也少有人入睡，大多会熬到半夜甚至于凌晨。有人来和我说晚上总是不想睡，一熬就熬到十二点，然而第二天早上却起不来，想想是很不可取的，大好的青春，为何要这样来挥霍呢，我连忙建议他不要再熬夜了。我的害怕熬夜源于打工的那段时间吧，记得那时上夜班，总是睡不够，有时累得坐着也能睡着，挺害怕身体就这样垮了，其实每一个人都一样，晚上早点睡，总没错，第二天精神好好的，早点起来，你信不信，渐渐地，就会有人对你竖大拇指了。再一件就是看恐怖片，总觉得那是一种虐心的东西，看那个总觉得很受折磨，在一段时间里总是会想到那些画面，想想又何必呢，心情，要保持平和，其实也没必要找些恐怖片来使之波动。对我来说，生活已经够刺激的了，我喜欢看那些有深刻意义的，能给我心灵上思想上以启迪的电影…… 第二件事：关于爱情 曾经有人问我：如果一个男生和一个女生注视15秒，结果会怎样？我回答，会挨一巴掌吧……玩笑之余，我也想或许对于我自己而言，还没有对恋爱有多么大的诉求，而我也没有真正地经历过一场恋爱。我理解的恋爱，在高中似乎确实有些懵懂，而在大学则有些热烈，走向社会后或许又会有一些对现实的屈服。对于在高中时见过的那些对恋爱的追求与体验，虽不知道现在究竟还有多少会仍旧在维系着，但我也会怀有美好的心灵寄予他们美好的祝福吧！现在在大学，也听过一些同学对恋爱的迷惑，或者也见过恋人的分分合合或是不离不弃，不管怎么样，相信在这个阶段，爱情，还是美好的。 有人来向我抱怨，爱情总是输给现实，现实有时又是那么残忍，为什么相爱的人不能在一起？想必很多人看过那些年，里面的主人公的爱情或许可以说是输给现实了吧。也有人遗憾，那时的柯景腾为何不去追沈佳宜，或许，那样的话他们就会在一起了。常常有人说，我们现在不谈一场恋爱，那等到以后，我们会忙于工作，忙于生计，那时又有什么时间去谈恋爱，那时的恋爱也许就没有多大的意义了吧。听到这样的话，也有感慨，可能现实就是这样，总是不能满足人们的需要。但是，我想，就像对于我们这一辈的父母辈，有多少是通过自由恋爱结合的，又有多少是在新婚夜见的第一面，可是他们一直在一起生活到了现在，我们可以说他们是不幸福的吗？或许现实在这件事情上又走了另一个极端：真正相爱的在一起了也不一定是幸福的，不是吗？ 第三件事：关于友情 在地域与时间的间隔下，以往的友情也许正在慢慢地淡化，被不断地稀释，在新的时间与空间里，或许已经有人走进了你的生活，或许你仍然是一个人独自地行走。漫长的四年大学之中你有很多时间和那些新的朋友在一起，或是说在这四年里，你们会朝夕相处，或是平平淡淡。有人来向我诉说和朋友之间的小矛盾，我简单的理解为是为了一些小事而闹得不开心，毕竟，两个朋友会有多少大事呢。我告诉他，记得吗？在高中时我也曾和你有过小矛盾，记得是你记恨我吧，不过那时是我主动向你沟通的，你知道是为什么吗？那时因为我在乎这一段友谊。我想说的是，假如你真的在乎你们之间的友谊，那么，要相信任何的小矛盾都是不会毁坏你们的友谊的，如果你在乎，那请你主动开口，相信你们的友谊会长久的。 可能这是一个必然的结果吧，最近又有一个朋友和我说他谈恋爱了。不知道是不是因为嫉妒或者是吃醋，心里总有一种淡淡的委屈与忧伤感，觉得从此以后我们的关系也就会渐渐的淡漠了。我告诉自己，这个应该是必然会发生的，不必太忧伤。或许友情没有爱情那般诱人，而我也只能默默地接受这样的结局吧！ 第四件事：关于成功 有人问我，现在在学校混的好的以后在社会一定能混的好吗？我想说的是，我不知道。我会承认，现在的我在大学里至今为止都没有混得一官半职，甚至连高中的状态都不如了，但是，我并不羡慕。或许曾经也参加过一些活动，但最终我还是选择了我想做的事而放弃了另一些。尽管这样，我仍然能看到那些参加了社团活动的同学，他们可以为一些小事旷了专业课而把社团工作看得最重，给我的感觉是他们似乎有些分不清孰轻孰重了。在这个像社会又不像社会的地方，有时候给人的感觉有些错乱，看看大学里的事情，有时候充满了虚假、充满了欺骗、充满了不情愿、充满了做作、充满了人情世故……这一切似乎不是一个需要讲学术的地方所应该有的，但它就是真真切切地存在着，无法逃避，只能面对，或也可以敬而远之。对于这些，我一直的态度是：既然待在社团，那就好好地工作，如果无法融入，那就离开吧，也不必遗憾什么。 或许我有时也觉得，我们的思想似乎有些偏转了。想当初，我们上高中，拼命地学习，其实，那时学的东西都是空的，对于我们未来的发展的用处可以说是微乎其微，可是，相比于我们现在所学的东西，我们以后却是可以靠它吃饭的，然而现实是努力学习的人却没有了，偶尔出现一个，也要冠以“学霸”的称号来戏谑一番，然后，继续放松学习，想必，这，便是大学的学习现状吧！我们都说，成功的方式有很多种，也会有很多种意义，最终总会有一种意义可以去阐述你那时所做的事情的意义，也许没有意义，也许意味深长，但那种感觉终将属于你，你要做的就是做你喜欢的事，追求你想要的生活。 第五件事：关于生命 突然有一天被问起：你想过自杀吗？我一惊，心里总不是滋味。想起一件事，一件真实的事件。在2011年暑假，我在一家餐馆打工，在那里认识了一位甘肃的小伙子，二十多岁，人还好，他也挺照顾我，在那里的一个多月的时间里，渐渐的熟悉。记得要开学的时候，我离开的那晚还和他一起喝酒。之后一直没见过。再次见面是在两年后了，也就是2013年的暑假的一晚，那一夜，同样的地点，我吃着晚饭，他突然出现来和我们说话，我也随便问了一句：嗨，你还记得我吗？他很热情，说记得。接下来，他就和在场的人说了一句话，让我现在还总觉得心惊胆战的一句话：我今晚就要死了，就算今晚不死，这几天也会死的。在场的人都以为他是开玩笑，还回应他说：你今晚是来和我们道别的吗？说了几句话，他就又走了。就在两天后，便传来他的死讯，据说是跳江自杀的。下班了，我急忙看新闻，新闻里是这样说的：死者男，姓杨，甘肃人，26岁左右……新闻画面播出的是尸体被打捞上岸的情景，只看得到半个被白布包裹的尸体，确认无疑是他了。据说他是在金华杀了人，被金华警方通缉，后来跳江自杀的。那一晚我总是不能平静，一想到这个画面，总是感慨万千，没想到两天前的晚上竟是我见他的最后一面，两天前活生生的人，两天后却变成了只能被抬走火化的尸体，人的生命竟是这样脆弱，变化又是如此剧烈。可是，就是这样一起死亡，在很多人眼里，却是“就像死一条狗一样”，其实，当我们撇开那些人性的善良与同情，那么这样的死亡确实是这样的，没有任何意义，像死一条狗一样。 我总也想不通那些自杀的人，到底要有多大的对生命的否定才会让一个人感觉只有选择结束生命才能解脱呢？我相信敬畏生命的人才会懂得生命、珍惜生命，我告诉那个说有过自杀想法的人：你要想想，你不在乎你自己，你还有你的父母、你的兄弟、你的朋友，那些你爱的人和爱你的人都需要你活着。生命，也只有在它存在时才会发光。 说了这么多，都是我自己心里的感想吧，随便说说……","permalink":"https://txiaozhe.github.io/2014/05/17/five-things-for-college/","photos":[]}]}